{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"115_hw_05-colab.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"lT-d5VEPYEfT"},"source":["# Курс Введение в обработку естественного языка / Практическое задание урока 5. Part-of-Speech разметка, NER, извлечение отношений"]},{"cell_type":"markdown","metadata":{"id":"IkpcHsV8RWHA"},"source":["## Задание 1"]},{"cell_type":"markdown","metadata":{"id":"aAQBOJRARev7"},"source":["**Написать теггер на данных с руским языком**\n","1. проверить UnigramTagger, BigramTagger, TrigramTagger и их комбмнации  \n","2. написать свой теггер как на занятии, но улучшить попробовать разные векторайзеры, добавить знание не только букв и слов но и совместно объединить эти признаки  \n","3. вместо векторайзеров взять эмбединги попробовать (word2vec и fasttext по желанию дополнительно можно взять tf.keras.layers.Embedding)  \n","4. взять не только эмбединги каждого слова, но и взять соседей, т.е. информацию о соседях количество соседей выбрать самим (узнать наилучшее количество соседей)    \n","5. сравнить все реализованные методы сделать выводы"]},{"cell_type":"markdown","metadata":{"id":"_16J0ER8WOJx"},"source":["### загрузка данных"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yPRx8Cu_RDY1","executionInfo":{"status":"ok","timestamp":1625681061966,"user_tz":-180,"elapsed":4489,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"8da3b709-60d6-489a-f955-9b983f7d59e0"},"source":["!pip install pyconll"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting pyconll\n","  Downloading https://files.pythonhosted.org/packages/0a/4c/edf12b4b211f8a0f7f85a52ed4b50cd453ac96e9b751427e0296eb7ae42a/pyconll-3.1.0-py3-none-any.whl\n","Installing collected packages: pyconll\n","Successfully installed pyconll-3.1.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9wgL-33mWUyZ","executionInfo":{"status":"ok","timestamp":1625681061968,"user_tz":-180,"elapsed":12,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["import pyconll"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"vXxwW9NzW570","executionInfo":{"status":"ok","timestamp":1625681061969,"user_tz":-180,"elapsed":12,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["!mkdir datasets"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tpwgA3svWiRw","executionInfo":{"status":"ok","timestamp":1625681064286,"user_tz":-180,"elapsed":2328,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"21e1f5ab-7fc4-4a9e-9039-8f5c028f6638"},"source":["!wget -O ./datasets/ru_syntagrus-ud-train.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train.conllu\n","!wget -O ./datasets/ru_syntagrus-ud-dev.conllu https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu"],"execution_count":4,"outputs":[{"output_type":"stream","text":["--2021-07-07 18:04:19--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train.conllu\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 81039282 (77M) [text/plain]\n","Saving to: ‘./datasets/ru_syntagrus-ud-train.conllu’\n","\n","./datasets/ru_synta 100%[===================>]  77.28M   106MB/s    in 0.7s    \n","\n","2021-07-07 18:04:21 (106 MB/s) - ‘./datasets/ru_syntagrus-ud-train.conllu’ saved [81039282/81039282]\n","\n","--2021-07-07 18:04:21--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 10902738 (10M) [text/plain]\n","Saving to: ‘./datasets/ru_syntagrus-ud-dev.conllu’\n","\n","./datasets/ru_synta 100%[===================>]  10.40M  --.-KB/s    in 0.1s    \n","\n","2021-07-07 18:04:21 (96.9 MB/s) - ‘./datasets/ru_syntagrus-ud-dev.conllu’ saved [10902738/10902738]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Oymo30RBWjjl","executionInfo":{"status":"ok","timestamp":1625681088703,"user_tz":-180,"elapsed":24421,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["full_train = pyconll.load_from_file('datasets/ru_syntagrus-ud-train.conllu')\n","full_test = pyconll.load_from_file('datasets/ru_syntagrus-ud-dev.conllu')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"XBzFe82cXGNK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625681088705,"user_tz":-180,"elapsed":13,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"4a8513ac-84f6-40ee-e562-b4cf9796ccbd"},"source":["for sent in full_train[:2]:\n","    for token in sent:\n","        print(token.form, token.upos)\n","    print()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Анкета NOUN\n",". PUNCT\n","\n","Начальник NOUN\n","областного ADJ\n","управления NOUN\n","связи NOUN\n","Семен PROPN\n","Еремеевич PROPN\n","был AUX\n","человек NOUN\n","простой ADJ\n",", PUNCT\n","приходил VERB\n","на ADP\n","работу NOUN\n","всегда ADV\n","вовремя ADV\n",", PUNCT\n","здоровался VERB\n","с ADP\n","секретаршей NOUN\n","за ADP\n","руку NOUN\n","и CCONJ\n","иногда ADV\n","даже PART\n","писал VERB\n","в ADP\n","стенгазету NOUN\n","заметки NOUN\n","под ADP\n","псевдонимом NOUN\n","\" PUNCT\n","Муха NOUN\n","\" PUNCT\n",". PUNCT\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZwfleTYJebpv"},"source":["## Решение"]},{"cell_type":"code","metadata":{"id":"uHzwiXUYftI_","executionInfo":{"status":"ok","timestamp":1625681090202,"user_tz":-180,"elapsed":1505,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["import nltk\n","\n","from nltk.corpus import brown\n","from nltk.tag import DefaultTagger\n","from nltk.tag import UnigramTagger\n","from nltk.tag import BigramTagger, TrigramTagger\n","from nltk.tag import RegexpTagger"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"tSi8niRiaJ3w","executionInfo":{"status":"ok","timestamp":1625681090204,"user_tz":-180,"elapsed":11,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["def conver_to_test_data(full):\n","    res = []\n","    for sent in full:\n","        sub_res = []\n","        for token in sent:\n","            sub_res.append((token.form, token.upos))\n","        res.append(sub_res)\n","    return res"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWlDy5Fxd3Gt","executionInfo":{"status":"ok","timestamp":1625681090205,"user_tz":-180,"elapsed":10,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["def conver_to_test_sent(full):\n","    res = []\n","    for sent in full:\n","        sub_res = []\n","        for token in sent:\n","            sub_res.append(token.form)\n","        res.append(sub_res)\n","    return res"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"YSmy1yrNeBF4","executionInfo":{"status":"ok","timestamp":1625681090997,"user_tz":-180,"elapsed":801,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["train_data = conver_to_test_data(full_train)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"vs39V07aemYu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625681091002,"user_tz":-180,"elapsed":23,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"4a63a364-b2f3-4a62-8e25-3dae1f886f5e"},"source":["test_data = conver_to_test_data(full_test)\n","print(test_data[0:10])"],"execution_count":11,"outputs":[{"output_type":"stream","text":["[[('Алгоритм', 'NOUN'), (',', 'PUNCT'), ('от', 'ADP'), ('имени', 'NOUN'), ('учёного', 'NOUN'), ('аль', 'PART'), ('-', 'PUNCT'), ('Хорезми', 'PROPN'), (',', 'PUNCT'), ('-', 'PUNCT'), ('точный', 'ADJ'), ('набор', 'NOUN'), ('инструкций', 'NOUN'), (',', 'PUNCT'), ('описывающих', 'VERB'), ('порядок', 'NOUN'), ('действий', 'NOUN'), ('исполнителя', 'NOUN'), ('для', 'ADP'), ('достижения', 'NOUN'), ('результата', 'NOUN'), ('решения', 'NOUN'), ('задачи', 'NOUN'), ('за', 'ADP'), ('конечное', 'ADJ'), ('время', 'NOUN'), ('.', 'PUNCT')], [('В', 'ADP'), ('старой', 'ADJ'), ('трактовке', 'NOUN'), ('вместо', 'ADP'), ('слова', 'NOUN'), ('\"', 'PUNCT'), ('порядок', 'NOUN'), ('\"', 'PUNCT'), ('использовалось', 'VERB'), ('слово', 'NOUN'), ('\"', 'PUNCT'), ('последовательность', 'NOUN'), ('\"', 'PUNCT'), (',', 'PUNCT'), ('но', 'CCONJ'), ('по', 'ADP'), ('мере', 'NOUN'), ('развития', 'NOUN'), ('параллельности', 'NOUN'), ('в', 'ADP'), ('работе', 'NOUN'), ('компьютеров', 'NOUN'), ('слово', 'NOUN'), ('\"', 'PUNCT'), ('последовательность', 'NOUN'), ('\"', 'PUNCT'), ('стали', 'VERB'), ('заменять', 'VERB'), ('более', 'ADV'), ('общим', 'ADJ'), ('словом', 'NOUN'), ('\"', 'PUNCT'), ('порядок', 'NOUN'), ('\"', 'PUNCT'), ('.', 'PUNCT')], [('Это', 'PRON'), ('связано', 'VERB'), ('с', 'ADP'), ('тем', 'PRON'), (',', 'PUNCT'), ('что', 'SCONJ'), ('работа', 'NOUN'), ('каких-то', 'DET'), ('инструкций', 'NOUN'), ('алгоритма', 'NOUN'), ('может', 'VERB'), ('быть', 'AUX'), ('зависима', 'ADJ'), ('от', 'ADP'), ('других', 'ADJ'), ('инструкций', 'NOUN'), ('или', 'CCONJ'), ('результатов', 'NOUN'), ('их', 'DET'), ('работы', 'NOUN'), ('.', 'PUNCT')], [('Таким', 'DET'), ('образом', 'NOUN'), (',', 'PUNCT'), ('некоторые', 'DET'), ('инструкции', 'NOUN'), ('должны', 'ADJ'), ('выполняться', 'VERB'), ('строго', 'ADV'), ('после', 'ADP'), ('завершения', 'NOUN'), ('работы', 'NOUN'), ('инструкций', 'NOUN'), (',', 'PUNCT'), ('от', 'ADP'), ('которых', 'PRON'), ('они', 'PRON'), ('зависят', 'VERB'), ('.', 'PUNCT')], [('Независимые', 'ADJ'), ('инструкции', 'NOUN'), ('или', 'CCONJ'), ('инструкции', 'NOUN'), (',', 'PUNCT'), ('ставшие', 'VERB'), ('независимыми', 'ADJ'), ('из-за', 'ADP'), ('завершения', 'NOUN'), ('работы', 'NOUN'), ('инструкций', 'NOUN'), (',', 'PUNCT'), ('от', 'ADP'), ('которых', 'PRON'), ('они', 'PRON'), ('зависят', 'VERB'), (',', 'PUNCT'), ('могут', 'VERB'), ('выполняться', 'VERB'), ('в', 'ADP'), ('произвольном', 'ADJ'), ('порядке', 'NOUN'), (',', 'PUNCT'), ('параллельно', 'ADV'), ('или', 'CCONJ'), ('одновременно', 'ADV'), (',', 'PUNCT'), ('если', 'SCONJ'), ('это', 'PRON'), ('позволяют', 'VERB'), ('используемые', 'VERB'), ('процессор', 'NOUN'), ('и', 'CCONJ'), ('операционная', 'ADJ'), ('система', 'NOUN'), ('.', 'PUNCT')], [('Ранее', 'ADV'), ('часто', 'ADV'), ('писали', 'VERB'), ('\"', 'PUNCT'), ('алгорифм', 'NOUN'), ('\"', 'PUNCT'), (',', 'PUNCT'), ('сейчас', 'ADV'), ('такое', 'DET'), ('написание', 'NOUN'), ('используется', 'VERB'), ('редко', 'ADV'), (',', 'PUNCT'), ('но', 'CCONJ'), (',', 'PUNCT'), ('тем', 'PRON'), ('не', 'PART'), ('менее', 'ADV'), (',', 'PUNCT'), ('имеет', 'VERB'), ('место', 'NOUN'), ('(', 'PUNCT'), ('например', 'ADV'), (',', 'PUNCT'), ('Нормальный', 'ADJ'), ('алгорифм', 'NOUN'), ('Маркова', 'PROPN'), (')', 'PUNCT'), ('.', 'PUNCT')], [('Часто', 'ADV'), ('в', 'ADP'), ('качестве', 'NOUN'), ('исполнителя', 'NOUN'), ('выступает', 'VERB'), ('некоторый', 'DET'), ('механизм', 'NOUN'), ('(', 'PUNCT'), ('компьютер', 'NOUN'), (',', 'PUNCT'), ('токарный', 'ADJ'), ('станок', 'NOUN'), (',', 'PUNCT'), ('швейная', 'ADJ'), ('машина', 'NOUN'), (')', 'PUNCT'), (',', 'PUNCT'), ('но', 'CCONJ'), ('понятие', 'NOUN'), ('алгоритма', 'NOUN'), ('необязательно', 'ADV'), ('относится', 'VERB'), ('к', 'ADP'), ('компьютерным', 'ADJ'), ('программам', 'NOUN'), (',', 'PUNCT'), ('так', 'ADV'), (',', 'PUNCT'), ('например', 'ADV'), (',', 'PUNCT'), ('чётко', 'ADV'), ('описанный', 'VERB'), ('рецепт', 'NOUN'), ('приготовления', 'NOUN'), ('блюда', 'NOUN'), ('также', 'ADV'), ('является', 'VERB'), ('алгоритмом', 'NOUN'), (',', 'PUNCT'), ('в', 'ADP'), ('таком', 'DET'), ('случае', 'NOUN'), ('исполнителем', 'NOUN'), ('является', 'VERB'), ('человек', 'NOUN'), ('.', 'PUNCT')], [('Определения', 'NOUN'), ('алгоритма', 'NOUN'), ('.', 'PUNCT')], [('Единого', 'ADJ'), ('\"', 'PUNCT'), ('истинного', 'ADJ'), ('\"', 'PUNCT'), ('определения', 'NOUN'), ('понятия', 'NOUN'), ('\"', 'PUNCT'), ('алгоритм', 'NOUN'), ('\"', 'PUNCT'), ('нет', 'VERB'), ('.', 'PUNCT')], [('\"', 'PUNCT'), ('Алгоритм', 'NOUN'), ('-', 'PUNCT'), ('это', 'PRON'), ('конечный', 'ADJ'), ('набор', 'NOUN'), ('правил', 'NOUN'), (',', 'PUNCT'), ('который', 'PRON'), ('определяет', 'VERB'), ('последовательность', 'NOUN'), ('операций', 'NOUN'), ('для', 'ADP'), ('решения', 'NOUN'), ('конкретного', 'ADJ'), ('множества', 'NOUN'), ('задач', 'NOUN'), ('и', 'CCONJ'), ('обладает', 'VERB'), ('пятью', 'NUM'), ('важными', 'ADJ'), ('чертами', 'NOUN'), (':', 'PUNCT'), ('конечность', 'NOUN'), (',', 'PUNCT'), ('определённость', 'NOUN'), (',', 'PUNCT'), ('ввод', 'NOUN'), (',', 'PUNCT'), ('вывод', 'NOUN'), (',', 'PUNCT'), ('эффективность', 'NOUN'), ('\"', 'PUNCT'), ('.', 'PUNCT'), ('(', 'PUNCT'), ('Д.', 'PROPN'), ('Э.', 'PROPN'), ('Кнут', 'PROPN'), (')', 'PUNCT'), ('.', 'PUNCT')]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5LUEMNtLez-4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625681091003,"user_tz":-180,"elapsed":19,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"9b6589f4-cbb4-484d-bffe-c8304452881a"},"source":["test_sent = conver_to_test_sent(full_test)[0]\n","print(test_sent)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["['Алгоритм', ',', 'от', 'имени', 'учёного', 'аль', '-', 'Хорезми', ',', '-', 'точный', 'набор', 'инструкций', ',', 'описывающих', 'порядок', 'действий', 'исполнителя', 'для', 'достижения', 'результата', 'решения', 'задачи', 'за', 'конечное', 'время', '.']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"IWSwxjTmZSK3"},"source":["### 1.Проверить UnigramTagger, BigramTagger, TrigramTagger и их комбинации"]},{"cell_type":"code","metadata":{"id":"OshO48XLXQar","colab":{"base_uri":"https://localhost:8080/","height":515},"executionInfo":{"status":"ok","timestamp":1625681096436,"user_tz":-180,"elapsed":5441,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"43faeeb3-41b0-4182-e440-a0a3cfc2a66c"},"source":["unigram_tagger = UnigramTagger(train_data)\n","display(unigram_tagger.tag(test_sent), unigram_tagger.evaluate(test_data))"],"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":["[('Алгоритм', None),\n"," (',', 'PUNCT'),\n"," ('от', 'ADP'),\n"," ('имени', 'NOUN'),\n"," ('учёного', 'NOUN'),\n"," ('аль', 'PART'),\n"," ('-', 'PUNCT'),\n"," ('Хорезми', None),\n"," (',', 'PUNCT'),\n"," ('-', 'PUNCT'),\n"," ('точный', 'ADJ'),\n"," ('набор', 'NOUN'),\n"," ('инструкций', 'NOUN'),\n"," (',', 'PUNCT'),\n"," ('описывающих', 'VERB'),\n"," ('порядок', 'NOUN'),\n"," ('действий', 'NOUN'),\n"," ('исполнителя', 'NOUN'),\n"," ('для', 'ADP'),\n"," ('достижения', 'NOUN'),\n"," ('результата', 'NOUN'),\n"," ('решения', 'NOUN'),\n"," ('задачи', 'NOUN'),\n"," ('за', 'ADP'),\n"," ('конечное', None),\n"," ('время', 'NOUN'),\n"," ('.', 'PUNCT')]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["0.8772537323492737"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"dj4tV8ytXTry","colab":{"base_uri":"https://localhost:8080/","height":515},"executionInfo":{"status":"ok","timestamp":1625681102657,"user_tz":-180,"elapsed":6225,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"e614a4af-e784-4031-b136-e99255e2b78e"},"source":["bigram_tagger = BigramTagger(train_data, backoff=unigram_tagger)\n","display(bigram_tagger.tag(test_sent), bigram_tagger.evaluate(test_data))"],"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["[('Алгоритм', None),\n"," (',', 'PUNCT'),\n"," ('от', 'ADP'),\n"," ('имени', 'NOUN'),\n"," ('учёного', 'NOUN'),\n"," ('аль', 'PART'),\n"," ('-', 'PUNCT'),\n"," ('Хорезми', None),\n"," (',', 'PUNCT'),\n"," ('-', 'PUNCT'),\n"," ('точный', 'ADJ'),\n"," ('набор', 'NOUN'),\n"," ('инструкций', 'NOUN'),\n"," (',', 'PUNCT'),\n"," ('описывающих', 'VERB'),\n"," ('порядок', 'NOUN'),\n"," ('действий', 'NOUN'),\n"," ('исполнителя', 'NOUN'),\n"," ('для', 'ADP'),\n"," ('достижения', 'NOUN'),\n"," ('результата', 'NOUN'),\n"," ('решения', 'NOUN'),\n"," ('задачи', 'NOUN'),\n"," ('за', 'ADP'),\n"," ('конечное', None),\n"," ('время', 'NOUN'),\n"," ('.', 'PUNCT')]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["0.8829828463586425"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"spqg0o-LgWCA","colab":{"base_uri":"https://localhost:8080/","height":515},"executionInfo":{"status":"ok","timestamp":1625681110957,"user_tz":-180,"elapsed":8307,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"abcd3f65-97eb-42aa-9416-f231874bb240"},"source":["trigram_tagger = TrigramTagger(train_data, backoff=bigram_tagger)\n","display(trigram_tagger.tag(test_sent), trigram_tagger.evaluate(test_data))"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":["[('Алгоритм', None),\n"," (',', 'PUNCT'),\n"," ('от', 'ADP'),\n"," ('имени', 'NOUN'),\n"," ('учёного', 'NOUN'),\n"," ('аль', 'PART'),\n"," ('-', 'PUNCT'),\n"," ('Хорезми', None),\n"," (',', 'PUNCT'),\n"," ('-', 'PUNCT'),\n"," ('точный', 'ADJ'),\n"," ('набор', 'NOUN'),\n"," ('инструкций', 'NOUN'),\n"," (',', 'PUNCT'),\n"," ('описывающих', 'VERB'),\n"," ('порядок', 'NOUN'),\n"," ('действий', 'NOUN'),\n"," ('исполнителя', 'NOUN'),\n"," ('для', 'ADP'),\n"," ('достижения', 'NOUN'),\n"," ('результата', 'NOUN'),\n"," ('решения', 'NOUN'),\n"," ('задачи', 'NOUN'),\n"," ('за', 'ADP'),\n"," ('конечное', None),\n"," ('время', 'NOUN'),\n"," ('.', 'PUNCT')]"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"text/plain":["0.882081353418933"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"hs3qK-VNgqrH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625681131605,"user_tz":-180,"elapsed":20673,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"70c8e390-3765-4108-f575-020e9547962f"},"source":["# Комбинация тэггеров\n","def backoff_tagger(train_sents, tagger_classes, backoff=None):\n","    for cls in tagger_classes:\n","        backoff = cls(train_sents, backoff=backoff)\n","    return backoff\n","\n","\n","backoff = DefaultTagger('NN') \n","tag = backoff_tagger(train_data,  \n","                     [UnigramTagger, BigramTagger, TrigramTagger],  \n","                     backoff = backoff) \n","  \n","tag.evaluate(test_data)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.8814747413473528"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"BK-MGJLYhvOx"},"source":["### 2.Написать свой теггер как на занятии, но улучшить попробовать разные векторайзеры, добавить знание не только букв и слов но и совместно объединить эти признаки"]},{"cell_type":"code","metadata":{"id":"qs01YoOIkR4n","executionInfo":{"status":"ok","timestamp":1625681131606,"user_tz":-180,"elapsed":7,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n","\n","from sklearn.pipeline import make_pipeline\n","from sklearn.preprocessing import StandardScaler\n","\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.svm import SVC\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.preprocessing import LabelEncoder"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"2CP2Eu8Oii9U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625681133714,"user_tz":-180,"elapsed":2113,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"05534af1-0708-4fef-d40d-b712a60d90aa"},"source":["fdata_train = []\n","for sent in full_train[:]:\n","    fdata_train.append([(token.form.lower(), token.upos) for token in sent])\n","    \n","fdata_test = []\n","for sent in full_test[:]:\n","    fdata_test.append([(token.form.lower(), token.upos) for token in sent])\n","    \n","fdata_sent_train = []\n","for sent in full_train[:]:\n","    fdata_sent_train.append([token.form.lower() for token in sent])\n","    \n","fdata_sent_test = []\n","for sent in full_test[:]:\n","    fdata_sent_test.append([token.form.lower() for token in sent])\n","    \n","    \n","MAX_SENT_LEN = max(len(sent) for sent in full_train)\n","MAX_ORIG_TOKEN_LEN = max(len(token.form) for sent in full_train for token in sent)\n","print('Наибольшая длина предложения', MAX_SENT_LEN)\n","print('Наибольшая длина токена', MAX_ORIG_TOKEN_LEN)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Наибольшая длина предложения 205\n","Наибольшая длина токена 47\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RUoLh3i9i7of","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625681134671,"user_tz":-180,"elapsed":963,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"13de87c3-3584-4814-9205-e7800b09c8a2"},"source":["train_tok = []\n","train_label = []\n","for sent in fdata_train[:]:\n","    for tok in sent:\n","        train_tok.append(tok[0])\n","        train_label.append('NO_TAG' if tok[1] is None else tok[1])\n","        \n","test_tok = []\n","test_label = []\n","for sent in fdata_test[:]:\n","    for tok in sent:\n","        test_tok.append(tok[0])\n","        test_label.append('NO_TAG' if tok[1] is None else tok[1])\n","\n","le = LabelEncoder()\n","train_enc_labels = le.fit_transform(train_label) \n","test_enc_labels = le.transform(test_label)\n","le.classes_"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN',\n","       'NO_TAG', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM',\n","       'VERB', 'X'], dtype='<U6')"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"13k3JKnMjGpr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625682168127,"user_tz":-180,"elapsed":1033459,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"517cc0e1-c734-4b52-c0fc-81fea6592f71"},"source":["# берем разные векторайзеры, анализируем по буквам\n","for vectorizer in [CountVectorizer, HashingVectorizer, TfidfVectorizer]:\n","\n","    scaler = StandardScaler(with_mean=False)\n","    coder = vectorizer(ngram_range=(1, 5), analyzer='char')\n","    \n","\n","    X_train = coder.fit_transform(train_tok)\n","    X_test = coder.transform(test_tok)\n","    \n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.fit_transform(X_test)    \n","    \n","    \n","    print(X_train.shape)\n","    lr = LogisticRegression(random_state=0, max_iter = 100, n_jobs=7)\n","    lr.fit(X_train, train_enc_labels)\n","\n","    pred = lr.predict(X_test)\n","\n","    print(vectorizer, accuracy_score(test_enc_labels, pred))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["(871526, 149809)\n","<class 'sklearn.feature_extraction.text.CountVectorizer'> 0.943644053516665\n","(871526, 1048576)\n","<class 'sklearn.feature_extraction.text.HashingVectorizer'> 0.9471826239342163\n","(871526, 149809)\n","<class 'sklearn.feature_extraction.text.TfidfVectorizer'> 0.9487749806221144\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"oCUF1KMgjLy9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625682918322,"user_tz":-180,"elapsed":750208,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"15932d5a-fa46-4872-8cbd-738283a66163"},"source":["# берем разные векторайзеры, анализируем по словам\n","for vectorizer in [CountVectorizer, HashingVectorizer, TfidfVectorizer]:\n","\n","    scaler = StandardScaler(with_mean=False)\n","    coder = vectorizer(ngram_range=(1, 5), analyzer='word')\n","    \n","\n","    X_train = coder.fit_transform(train_tok)\n","    X_test = coder.transform(test_tok)\n","    \n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.fit_transform(X_test)    \n","    \n","    \n","    print(X_train.shape)\n","    lr = LogisticRegression(random_state=0, max_iter = 100, n_jobs=7)\n","    lr.fit(X_train, train_enc_labels)\n","\n","    pred = lr.predict(X_test)\n","\n","    print(vectorizer, accuracy_score(test_enc_labels, pred))"],"execution_count":21,"outputs":[{"output_type":"stream","text":["(871526, 99485)\n","<class 'sklearn.feature_extraction.text.CountVectorizer'> 0.7531847133757962\n","(871526, 1048576)\n","<class 'sklearn.feature_extraction.text.HashingVectorizer'> 0.7722255922892866\n","(871526, 99485)\n","<class 'sklearn.feature_extraction.text.TfidfVectorizer'> 0.7532605398847437\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yl8x7Vk3jdyx","executionInfo":{"status":"ok","timestamp":1625683544165,"user_tz":-180,"elapsed":613009,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"f9b748eb-c59b-47ef-c86f-8940a0151b58"},"source":["# В случае совмещения двух признаков (буквы, слова) код успешно отработал только при первом запуске\n","# При последующих запусках выдавал ошибку. \n","# Для ликвидации ошибки делалось уменьшение n_jobs. \n","# После запуска в другой день и установки  n_jobs=4 ошибка не выдалась.\n","import numpy as np\n","from scipy.sparse import hstack\n","\n","# берем векторайзер TfidfVectorizer по буквам и HashingVectorizer по словам\n","scaler = StandardScaler(with_mean=False)\n","coder_1 = TfidfVectorizer(ngram_range=(1, 5), analyzer='char')\n","coder_2 = HashingVectorizer(ngram_range=(1, 5), analyzer='word')\n","\n","X_train_1 = coder_1.fit_transform(train_tok)\n","X_test_1 = coder_1.transform(test_tok)\n","\n","X_train_2 = coder_2.fit_transform(train_tok)\n","X_test_2 = coder_2.transform(test_tok)\n","\n","\n","X_train = hstack((X_train_1,X_train_2))\n","X_test = hstack((X_test_1,X_test_2))\n","\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.fit_transform(X_test)    \n","\n","\n","print(X_train.shape)\n","lr = LogisticRegression(random_state=0, max_iter = 100, n_jobs=4)\n","lr.fit(X_train, train_enc_labels)\n","\n","pred = lr.predict(X_test)\n","\n","print('TfidfVectorizer_char + HashingVectorizer_word :', accuracy_score(test_enc_labels, pred))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["(871526, 1198385)\n","TfidfVectorizer_char + HashingVectorizer_word : 0.9441327132409935\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FcC3NCmdvURC"},"source":["### 3.Вместо векторайзеров взять эмбединги попробовать (word2vec и fasttext по желанию дополнительно можно взять tf.keras.layers.Embedding)"]},{"cell_type":"code","metadata":{"id":"B0gILQZqyZCh","executionInfo":{"status":"ok","timestamp":1625683881242,"user_tz":-180,"elapsed":1196,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["import gensim"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"um4dnCGL3ryx"},"source":["#### word2vec"]},{"cell_type":"code","metadata":{"id":"0-FcVYByvc4m","executionInfo":{"status":"ok","timestamp":1625683884499,"user_tz":-180,"elapsed":5,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["train_word2vec = fdata_sent_train\n","train_word2vec.extend(fdata_sent_test)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9niuMXfvdDM","executionInfo":{"status":"ok","timestamp":1625683968607,"user_tz":-180,"elapsed":82086,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"ba52dbf9-1566-46ae-d632-c88c8811dc7b"},"source":["w2v_model = gensim.models.Word2Vec(min_count=1, negative=20, sg=1, window=2)\n","w2v_model.build_vocab(train_word2vec)\n","w2v_model.train(train_word2vec, epochs=5, total_examples=w2v_model.corpus_count)"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(3850208, 4951090)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"XReGHwQXvl07","executionInfo":{"status":"ok","timestamp":1625683974144,"user_tz":-180,"elapsed":2272,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["X_train_w2v = [w2v_model.wv[word] for word in train_tok]\n","X_test_w2v = [w2v_model.wv[word] for word in test_tok]"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNEObdnBvl5j","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625684041482,"user_tz":-180,"elapsed":64794,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"e927338e-2f6a-4a66-b1af-3b8b011abc99"},"source":["lr = LogisticRegression(random_state=0, max_iter=35) # max_iter изменено с 25 на 35\n","lr.fit(X_train_w2v, train_enc_labels)\n","pred = lr.predict(X_test_w2v)\n","accuracy_score(test_enc_labels, pred)"],"execution_count":27,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0.7469837899774205"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"y6J-csTOv93p"},"source":["#### fasttext"]},{"cell_type":"code","metadata":{"id":"YvIDDxfuvmFO","executionInfo":{"status":"ok","timestamp":1625684777967,"user_tz":-180,"elapsed":170140,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["ft_model = gensim.models.FastText(train_word2vec, min_count=1, negative=20, sg=1, window=5)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"J_KlvuR0jlKI","executionInfo":{"status":"ok","timestamp":1625684789354,"user_tz":-180,"elapsed":2869,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["X_train_ft = [ft_model.wv[word] for word in train_tok]\n","X_test_ft = [ft_model.wv[word] for word in test_tok]"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lin_tB14wFRL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625684852135,"user_tz":-180,"elapsed":59317,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"deedead4-2df0-42c1-ebdd-ddf07bd39b3c"},"source":["lr = LogisticRegression(random_state=0, max_iter=35) # max_iter изменено с 25 на 35\n","lr.fit(X_train_ft, train_enc_labels)\n","pred = lr.predict(X_test_ft)\n","accuracy_score(test_enc_labels, pred)"],"execution_count":30,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n","STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n","\n","Increase the number of iterations (max_iter) or scale the data as shown in:\n","    https://scikit-learn.org/stable/modules/preprocessing.html\n","Please also refer to the documentation for alternative solver options:\n","    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n","  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0.8727631179860479"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"oNa-Hmll0I79"},"source":["#### 4.взять не только эмбединги каждого слова, но и взять соседей, т.е. информацию о соседях количество соседей выбрать самим (узнать наилучшее количество соседей)"]},{"cell_type":"code","metadata":{"id":"7UjTFqAd0OFq","executionInfo":{"status":"ok","timestamp":1625684878076,"user_tz":-180,"elapsed":248,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"TAvF7GMW2TVW","executionInfo":{"status":"ok","timestamp":1625684880556,"user_tz":-180,"elapsed":268,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["lr = LogisticRegression(random_state=0, max_iter=25)"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"4f8Xts-j1ACH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625686415188,"user_tz":-180,"elapsed":1531980,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"7b29d4a1-49e2-4624-d62f-c18f5a99c6ec"},"source":["windows = [1,2,3,4,5,6,7,8,9]\n","for i in windows:\n","    w2v_model = gensim.models.Word2Vec(min_count=1, negative=20, sg=1, window=i)\n","    w2v_model.build_vocab(train_word2vec)\n","    w2v_model.train(train_word2vec, epochs=5, total_examples=w2v_model.corpus_count)\n","    X_train_w2v = [w2v_model.wv[word] for word in train_tok]\n","    X_test_w2v = [w2v_model.wv[word] for word in test_tok]\n","    lr.fit(X_train_w2v, train_enc_labels)\n","    pred = lr.predict(X_test_w2v)\n","    print('word2vec, window=', i, accuracy_score(test_enc_labels, pred))"],"execution_count":33,"outputs":[{"output_type":"stream","text":["word2vec, window= 1 0.7483992181444411\n","word2vec, window= 2 0.7394432649209719\n","word2vec, window= 3 0.7370505173052944\n","word2vec, window= 4 0.7279766117345735\n","word2vec, window= 5 0.7279681865669126\n","word2vec, window= 6 0.7235449735449735\n","word2vec, window= 7 0.7155242139318573\n","word2vec, window= 8 0.7166868870690527\n","word2vec, window= 9 0.7158696458059516\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e46O5GO90OPy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625419228656,"user_tz":-180,"elapsed":1375243,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"3ded17e7-6a93-4e45-a656-6276b12cba4d"},"source":["windows = [1,2,3,4,5,6,7,8,9]\n","for i in windows:\n","    ft_model = gensim.models.FastText(train_word2vec, min_count=1, negative=20, sg=1, window=i)\n","    X_train_ft = [ft_model.wv[word] for word in train_tok]\n","    X_test_ft = [ft_model.wv[word] for word in test_tok]\n","    lr.fit(X_train_ft, train_enc_labels)\n","    pred = lr.predict(X_test_ft)\n","    print('fasttext, window=', i, accuracy_score(test_enc_labels, pred))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["fasttext, window= 1 0.8582886799447309\n","fasttext, window= 2 0.864000943618778\n","fasttext, window= 3 0.8595440299261955\n","fasttext, window= 4 0.8590553702018671\n","fasttext, window= 5 0.8587015131601119\n","fasttext, window= 6 0.851380042462845\n","fasttext, window= 7 0.8503100461699188\n","fasttext, window= 8 0.8453476224176861\n","fasttext, window= 9 0.8446651838371584\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8jqUCMqogZr6"},"source":["#### 5.сравнить все реализованные методы сделать выводы"]},{"cell_type":"markdown","metadata":{"id":"bNHqFMrhgvbi"},"source":["* 0.88147 - скор по комбинации из UnigramTagger BigramTagger TrigramTagger при методе nltk.tag\n","* 0.94877 - скор LogisticRegression в сочетании с TfidfVectorizer по буквам при методе Vectorizer\n","* 0.86400 - скор LogisticRegression в сочетании с  FastText по window= 2 при методе эмбедингов \n","\n","**Вывод:**\n","* для рассматриваемого корпуса наилучшим является исследование по буквам, а не по словам \n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"Oo3zvsJ20Ob1"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cINqgGpKXURp"},"source":["# Задание 2"]},{"cell_type":"markdown","metadata":{"id":"VCM0drjKXYet"},"source":["много дополнительных датасетов на русском языке\n","\n","https://natasha.github.io/corus/  \n","https://github.com/natasha/corus"]},{"cell_type":"markdown","metadata":{"id":"sUOg4C8sZNpw"},"source":["мы будем использовать данные http://www.labinform.ru/pub/named_entities/"]},{"cell_type":"markdown","metadata":{"id":"qzi6ApNLZg6X"},"source":["**Проверить насколько хорошо работает NER**\n","\n","1. взять нер из nltk\n","2. проверить deeppavlov\n","3. написать свой нер попробовать разные подходы (с доп информацией без) так же с учётом соседей и без них\n","4. сделать выводы по вашим экспериментам какой из подходов успешнее справляется"]},{"cell_type":"markdown","metadata":{"id":"aP1LgaNUtaOz"},"source":["при обучении своего нера не забудьте разделить выборку"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qg6tcss2Zhp9","executionInfo":{"status":"ok","timestamp":1625686495595,"user_tz":-180,"elapsed":6990,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"ade26b9a-bb72-4850-803d-6215995feb6d"},"source":["!pip install corus"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Collecting corus\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e4/a3/e680679c669b0118271ac7246549c75a7088ab0e6696a3561408a3f9b50d/corus-0.9.0-py3-none-any.whl (83kB)\n","\u001b[K     |████████████████████████████████| 92kB 807kB/s \n","\u001b[?25hInstalling collected packages: corus\n","Successfully installed corus-0.9.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hrc5ocDkaS1e","executionInfo":{"status":"ok","timestamp":1625686498282,"user_tz":-180,"elapsed":269,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["import corus"],"execution_count":35,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vPVv6lhT3ftA","executionInfo":{"status":"ok","timestamp":1625686506386,"user_tz":-180,"elapsed":5632,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"1de8ec61-da5b-49c4-b5ae-51de31405f72"},"source":["!wget http://www.labinform.ru/pub/named_entities/collection5.zip"],"execution_count":36,"outputs":[{"output_type":"stream","text":["--2021-07-07 19:35:00--  http://www.labinform.ru/pub/named_entities/collection5.zip\n","Resolving www.labinform.ru (www.labinform.ru)... 80.240.100.4\n","Connecting to www.labinform.ru (www.labinform.ru)|80.240.100.4|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1899530 (1.8M) [application/zip]\n","Saving to: ‘collection5.zip’\n","\n","collection5.zip     100%[===================>]   1.81M   411KB/s    in 4.5s    \n","\n","2021-07-07 19:35:05 (411 KB/s) - ‘collection5.zip’ saved [1899530/1899530]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XtLK4z9CH2Ph","executionInfo":{"status":"ok","timestamp":1625686510135,"user_tz":-180,"elapsed":676,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"3cb22fd2-c144-4b7b-8b58-7513629e4835"},"source":["!unzip collection5.zip"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Archive:  collection5.zip\n","   creating: Collection5/\n","  inflating: Collection5/001.ann     \n","  inflating: Collection5/001.txt     \n","  inflating: Collection5/002.ann     \n","  inflating: Collection5/002.txt     \n","  inflating: Collection5/003.ann     \n","  inflating: Collection5/003.txt     \n","  inflating: Collection5/004.ann     \n","  inflating: Collection5/004.txt     \n","  inflating: Collection5/005.ann     \n","  inflating: Collection5/005.txt     \n","  inflating: Collection5/006.ann     \n","  inflating: Collection5/006.txt     \n","  inflating: Collection5/007.ann     \n","  inflating: Collection5/007.txt     \n","  inflating: Collection5/008.ann     \n","  inflating: Collection5/008.txt     \n","  inflating: Collection5/009.ann     \n","  inflating: Collection5/009.txt     \n","  inflating: Collection5/010.ann     \n","  inflating: Collection5/010.txt     \n","  inflating: Collection5/011.ann     \n","  inflating: Collection5/011.txt     \n","  inflating: Collection5/012.ann     \n","  inflating: Collection5/012.txt     \n","  inflating: Collection5/013.ann     \n","  inflating: Collection5/013.txt     \n","  inflating: Collection5/014.ann     \n","  inflating: Collection5/014.txt     \n","  inflating: Collection5/015 (!).ann  \n","  inflating: Collection5/015 (!).txt  \n","  inflating: Collection5/016.ann     \n","  inflating: Collection5/016.txt     \n","  inflating: Collection5/017.ann     \n","  inflating: Collection5/017.txt     \n","  inflating: Collection5/018.ann     \n","  inflating: Collection5/018.txt     \n","  inflating: Collection5/019.ann     \n","  inflating: Collection5/019.txt     \n","  inflating: Collection5/020.ann     \n","  inflating: Collection5/020.txt     \n","  inflating: Collection5/021.ann     \n","  inflating: Collection5/021.txt     \n","  inflating: Collection5/022.ann     \n","  inflating: Collection5/022.txt     \n","  inflating: Collection5/023.ann     \n","  inflating: Collection5/023.txt     \n","  inflating: Collection5/025.ann     \n","  inflating: Collection5/025.txt     \n","  inflating: Collection5/026.ann     \n","  inflating: Collection5/026.txt     \n","  inflating: Collection5/027.ann     \n","  inflating: Collection5/027.txt     \n","  inflating: Collection5/028.ann     \n","  inflating: Collection5/028.txt     \n","  inflating: Collection5/029.ann     \n","  inflating: Collection5/029.txt     \n","  inflating: Collection5/030.ann     \n","  inflating: Collection5/030.txt     \n","  inflating: Collection5/031.ann     \n","  inflating: Collection5/031.txt     \n","  inflating: Collection5/032.ann     \n","  inflating: Collection5/032.txt     \n","  inflating: Collection5/033.ann     \n","  inflating: Collection5/033.txt     \n","  inflating: Collection5/034.ann     \n","  inflating: Collection5/034.txt     \n","  inflating: Collection5/035.ann     \n","  inflating: Collection5/035.txt     \n","  inflating: Collection5/036.ann     \n","  inflating: Collection5/036.txt     \n","  inflating: Collection5/037.ann     \n","  inflating: Collection5/037.txt     \n","  inflating: Collection5/038.ann     \n","  inflating: Collection5/038.txt     \n","  inflating: Collection5/039.ann     \n","  inflating: Collection5/039.txt     \n","  inflating: Collection5/03_12_12a.ann  \n","  inflating: Collection5/03_12_12a.txt  \n","  inflating: Collection5/03_12_12b.ann  \n","  inflating: Collection5/03_12_12b.txt  \n","  inflating: Collection5/03_12_12c.ann  \n","  inflating: Collection5/03_12_12c.txt  \n","  inflating: Collection5/03_12_12d.ann  \n","  inflating: Collection5/03_12_12d.txt  \n","  inflating: Collection5/03_12_12g.ann  \n","  inflating: Collection5/03_12_12g.txt  \n","  inflating: Collection5/03_12_12h.ann  \n","  inflating: Collection5/03_12_12h.txt  \n","  inflating: Collection5/040.ann     \n","  inflating: Collection5/040.txt     \n","  inflating: Collection5/041.ann     \n","  inflating: Collection5/041.txt     \n","  inflating: Collection5/042.ann     \n","  inflating: Collection5/042.txt     \n","  inflating: Collection5/043.ann     \n","  inflating: Collection5/043.txt     \n","  inflating: Collection5/044.ann     \n","  inflating: Collection5/044.txt     \n","  inflating: Collection5/045.ann     \n","  inflating: Collection5/045.txt     \n","  inflating: Collection5/046.ann     \n","  inflating: Collection5/046.txt     \n","  inflating: Collection5/047.ann     \n","  inflating: Collection5/047.txt     \n","  inflating: Collection5/048.ann     \n","  inflating: Collection5/048.txt     \n","  inflating: Collection5/049.ann     \n","  inflating: Collection5/049.txt     \n","  inflating: Collection5/04_02_13a_abdulatipov.ann  \n","  inflating: Collection5/04_02_13a_abdulatipov.txt  \n","  inflating: Collection5/04_03_13a_sorokin.ann  \n","  inflating: Collection5/04_03_13a_sorokin.txt  \n","  inflating: Collection5/04_12_12b.ann  \n","  inflating: Collection5/04_12_12b.txt  \n","  inflating: Collection5/04_12_12d.ann  \n","  inflating: Collection5/04_12_12d.txt  \n","  inflating: Collection5/04_12_12f.ann  \n","  inflating: Collection5/04_12_12f.txt  \n","  inflating: Collection5/04_12_12g.ann  \n","  inflating: Collection5/04_12_12g.txt  \n","  inflating: Collection5/04_12_12h_corr.ann  \n","  inflating: Collection5/04_12_12h_corr.txt  \n","  inflating: Collection5/050.ann     \n","  inflating: Collection5/050.txt     \n","  inflating: Collection5/051.ann     \n","  inflating: Collection5/051.txt     \n","  inflating: Collection5/052.ann     \n","  inflating: Collection5/052.txt     \n","  inflating: Collection5/053.ann     \n","  inflating: Collection5/053.txt     \n","  inflating: Collection5/054.ann     \n","  inflating: Collection5/054.txt     \n","  inflating: Collection5/055.ann     \n","  inflating: Collection5/055.txt     \n","  inflating: Collection5/056.ann     \n","  inflating: Collection5/056.txt     \n","  inflating: Collection5/057.ann     \n","  inflating: Collection5/057.txt     \n","  inflating: Collection5/058.ann     \n","  inflating: Collection5/058.txt     \n","  inflating: Collection5/059.ann     \n","  inflating: Collection5/059.txt     \n","  inflating: Collection5/060.ann     \n","  inflating: Collection5/060.txt     \n","  inflating: Collection5/061.ann     \n","  inflating: Collection5/061.txt     \n","  inflating: Collection5/062.ann     \n","  inflating: Collection5/062.txt     \n","  inflating: Collection5/063.ann     \n","  inflating: Collection5/063.txt     \n","  inflating: Collection5/064.ann     \n","  inflating: Collection5/064.txt     \n","  inflating: Collection5/065.ann     \n","  inflating: Collection5/065.txt     \n","  inflating: Collection5/066.ann     \n","  inflating: Collection5/066.txt     \n","  inflating: Collection5/067.ann     \n","  inflating: Collection5/067.txt     \n","  inflating: Collection5/068.ann     \n","  inflating: Collection5/068.txt     \n","  inflating: Collection5/069.ann     \n","  inflating: Collection5/069.txt     \n","  inflating: Collection5/070.ann     \n","  inflating: Collection5/070.txt     \n","  inflating: Collection5/071.ann     \n","  inflating: Collection5/071.txt     \n","  inflating: Collection5/072.ann     \n","  inflating: Collection5/072.txt     \n","  inflating: Collection5/073.ann     \n","  inflating: Collection5/073.txt     \n","  inflating: Collection5/074.ann     \n","  inflating: Collection5/074.txt     \n","  inflating: Collection5/075.ann     \n","  inflating: Collection5/075.txt     \n","  inflating: Collection5/076.ann     \n","  inflating: Collection5/076.txt     \n","  inflating: Collection5/077.ann     \n","  inflating: Collection5/077.txt     \n","  inflating: Collection5/078.ann     \n","  inflating: Collection5/078.txt     \n","  inflating: Collection5/079.ann     \n","  inflating: Collection5/079.txt     \n","  inflating: Collection5/080.ann     \n","  inflating: Collection5/080.txt     \n","  inflating: Collection5/081.ann     \n","  inflating: Collection5/081.txt     \n","  inflating: Collection5/082.ann     \n","  inflating: Collection5/082.txt     \n","  inflating: Collection5/083.ann     \n","  inflating: Collection5/083.txt     \n","  inflating: Collection5/084.ann     \n","  inflating: Collection5/084.txt     \n","  inflating: Collection5/085.ann     \n","  inflating: Collection5/085.txt     \n","  inflating: Collection5/086.ann     \n","  inflating: Collection5/086.txt     \n","  inflating: Collection5/087.ann     \n","  inflating: Collection5/087.txt     \n","  inflating: Collection5/088.ann     \n","  inflating: Collection5/088.txt     \n","  inflating: Collection5/089.ann     \n","  inflating: Collection5/089.txt     \n","  inflating: Collection5/090.ann     \n","  inflating: Collection5/090.txt     \n","  inflating: Collection5/091.ann     \n","  inflating: Collection5/091.txt     \n","  inflating: Collection5/092.ann     \n","  inflating: Collection5/092.txt     \n","  inflating: Collection5/093.ann     \n","  inflating: Collection5/093.txt     \n","  inflating: Collection5/094.ann     \n","  inflating: Collection5/094.txt     \n","  inflating: Collection5/095.ann     \n","  inflating: Collection5/095.txt     \n","  inflating: Collection5/096.ann     \n","  inflating: Collection5/096.txt     \n","  inflating: Collection5/097.ann     \n","  inflating: Collection5/097.txt     \n","  inflating: Collection5/098.ann     \n","  inflating: Collection5/098.txt     \n","  inflating: Collection5/099.ann     \n","  inflating: Collection5/099.txt     \n","  inflating: Collection5/09_01_13.ann  \n","  inflating: Collection5/09_01_13.txt  \n","  inflating: Collection5/09_01_13a.ann  \n","  inflating: Collection5/09_01_13a.txt  \n","  inflating: Collection5/09_01_13c.ann  \n","  inflating: Collection5/09_01_13c.txt  \n","  inflating: Collection5/09_01_13d.ann  \n","  inflating: Collection5/09_01_13d.txt  \n","  inflating: Collection5/09_01_13e.ann  \n","  inflating: Collection5/09_01_13e.txt  \n","  inflating: Collection5/09_01_13h.ann  \n","  inflating: Collection5/09_01_13h.txt  \n","  inflating: Collection5/09_01_13i.ann  \n","  inflating: Collection5/09_01_13i.txt  \n","  inflating: Collection5/100.ann     \n","  inflating: Collection5/100.txt     \n","  inflating: Collection5/1000.ann    \n","  inflating: Collection5/1000.txt    \n","  inflating: Collection5/1001.ann    \n","  inflating: Collection5/1001.txt    \n","  inflating: Collection5/1002.ann    \n","  inflating: Collection5/1002.txt    \n","  inflating: Collection5/1003.ann    \n","  inflating: Collection5/1003.txt    \n","  inflating: Collection5/1004.ann    \n","  inflating: Collection5/1004.txt    \n","  inflating: Collection5/1005.ann    \n","  inflating: Collection5/1005.txt    \n","  inflating: Collection5/1006.ann    \n","  inflating: Collection5/1006.txt    \n","  inflating: Collection5/1007.ann    \n","  inflating: Collection5/1007.txt    \n","  inflating: Collection5/1008.ann    \n","  inflating: Collection5/1008.txt    \n","  inflating: Collection5/1009.ann    \n","  inflating: Collection5/1009.txt    \n","  inflating: Collection5/101.ann     \n","  inflating: Collection5/101.txt     \n","  inflating: Collection5/1010.ann    \n","  inflating: Collection5/1010.txt    \n","  inflating: Collection5/1011.ann    \n","  inflating: Collection5/1011.txt    \n","  inflating: Collection5/1012.ann    \n","  inflating: Collection5/1012.txt    \n","  inflating: Collection5/1013.ann    \n","  inflating: Collection5/1013.txt    \n","  inflating: Collection5/1014.ann    \n","  inflating: Collection5/1014.txt    \n","  inflating: Collection5/1015.ann    \n","  inflating: Collection5/1015.txt    \n","  inflating: Collection5/1016.ann    \n","  inflating: Collection5/1016.txt    \n","  inflating: Collection5/1017.ann    \n","  inflating: Collection5/1017.txt    \n","  inflating: Collection5/1018.ann    \n","  inflating: Collection5/1018.txt    \n","  inflating: Collection5/1019.ann    \n","  inflating: Collection5/1019.txt    \n","  inflating: Collection5/102.ann     \n","  inflating: Collection5/102.txt     \n","  inflating: Collection5/1020.ann    \n","  inflating: Collection5/1020.txt    \n","  inflating: Collection5/1021.ann    \n","  inflating: Collection5/1021.txt    \n","  inflating: Collection5/1022.ann    \n","  inflating: Collection5/1022.txt    \n","  inflating: Collection5/1023.ann    \n","  inflating: Collection5/1023.txt    \n","  inflating: Collection5/1024.ann    \n","  inflating: Collection5/1024.txt    \n","  inflating: Collection5/1025.ann    \n","  inflating: Collection5/1025.txt    \n","  inflating: Collection5/1026.ann    \n","  inflating: Collection5/1026.txt    \n","  inflating: Collection5/1027.ann    \n","  inflating: Collection5/1027.txt    \n","  inflating: Collection5/1028.ann    \n","  inflating: Collection5/1028.txt    \n","  inflating: Collection5/1029.ann    \n","  inflating: Collection5/1029.txt    \n","  inflating: Collection5/103.ann     \n","  inflating: Collection5/103.txt     \n","  inflating: Collection5/1030.ann    \n","  inflating: Collection5/1030.txt    \n","  inflating: Collection5/1031.ann    \n","  inflating: Collection5/1031.txt    \n","  inflating: Collection5/1032.ann    \n","  inflating: Collection5/1032.txt    \n","  inflating: Collection5/1033.ann    \n","  inflating: Collection5/1033.txt    \n","  inflating: Collection5/1034.ann    \n","  inflating: Collection5/1034.txt    \n","  inflating: Collection5/1035.ann    \n","  inflating: Collection5/1035.txt    \n","  inflating: Collection5/1036.ann    \n","  inflating: Collection5/1036.txt    \n","  inflating: Collection5/1037.ann    \n","  inflating: Collection5/1037.txt    \n","  inflating: Collection5/1038.ann    \n","  inflating: Collection5/1038.txt    \n","  inflating: Collection5/1039.ann    \n","  inflating: Collection5/1039.txt    \n","  inflating: Collection5/104.ann     \n","  inflating: Collection5/104.txt     \n","  inflating: Collection5/1040.ann    \n","  inflating: Collection5/1040.txt    \n","  inflating: Collection5/1041.ann    \n","  inflating: Collection5/1041.txt    \n","  inflating: Collection5/1042.ann    \n","  inflating: Collection5/1042.txt    \n","  inflating: Collection5/1043.ann    \n","  inflating: Collection5/1043.txt    \n","  inflating: Collection5/1044.ann    \n","  inflating: Collection5/1044.txt    \n","  inflating: Collection5/1045.ann    \n","  inflating: Collection5/1045.txt    \n","  inflating: Collection5/1046.ann    \n","  inflating: Collection5/1046.txt    \n","  inflating: Collection5/1047.ann    \n","  inflating: Collection5/1047.txt    \n","  inflating: Collection5/1048.ann    \n","  inflating: Collection5/1048.txt    \n","  inflating: Collection5/1049.ann    \n","  inflating: Collection5/1049.txt    \n","  inflating: Collection5/105.ann     \n","  inflating: Collection5/105.txt     \n","  inflating: Collection5/1050.ann    \n","  inflating: Collection5/1050.txt    \n","  inflating: Collection5/106.ann     \n","  inflating: Collection5/106.txt     \n","  inflating: Collection5/107.ann     \n","  inflating: Collection5/107.txt     \n","  inflating: Collection5/108.ann     \n","  inflating: Collection5/108.txt     \n","  inflating: Collection5/109.ann     \n","  inflating: Collection5/109.txt     \n","  inflating: Collection5/10_01_13a.ann  \n","  inflating: Collection5/10_01_13a.txt  \n","  inflating: Collection5/10_01_13d.ann  \n","  inflating: Collection5/10_01_13d.txt  \n","  inflating: Collection5/10_01_13i.ann  \n","  inflating: Collection5/10_01_13i.txt  \n","  inflating: Collection5/110.ann     \n","  inflating: Collection5/110.txt     \n","  inflating: Collection5/1100.ann    \n","  inflating: Collection5/1100.txt    \n","  inflating: Collection5/1101.ann    \n","  inflating: Collection5/1101.txt    \n","  inflating: Collection5/1102.ann    \n","  inflating: Collection5/1102.txt    \n","  inflating: Collection5/1103.ann    \n","  inflating: Collection5/1103.txt    \n","  inflating: Collection5/1104.ann    \n","  inflating: Collection5/1104.txt    \n","  inflating: Collection5/1105.ann    \n","  inflating: Collection5/1105.txt    \n","  inflating: Collection5/1106.ann    \n","  inflating: Collection5/1106.txt    \n","  inflating: Collection5/1107.ann    \n","  inflating: Collection5/1107.txt    \n","  inflating: Collection5/1108.ann    \n","  inflating: Collection5/1108.txt    \n","  inflating: Collection5/1109.ann    \n","  inflating: Collection5/1109.txt    \n","  inflating: Collection5/111.ann     \n","  inflating: Collection5/111.txt     \n","  inflating: Collection5/1110.ann    \n","  inflating: Collection5/1110.txt    \n","  inflating: Collection5/1111.ann    \n","  inflating: Collection5/1111.txt    \n","  inflating: Collection5/1112.ann    \n","  inflating: Collection5/1112.txt    \n","  inflating: Collection5/1113.ann    \n","  inflating: Collection5/1113.txt    \n","  inflating: Collection5/1114.ann    \n","  inflating: Collection5/1114.txt    \n","  inflating: Collection5/1115.ann    \n","  inflating: Collection5/1115.txt    \n","  inflating: Collection5/1116.ann    \n","  inflating: Collection5/1116.txt    \n","  inflating: Collection5/1117.ann    \n","  inflating: Collection5/1117.txt    \n","  inflating: Collection5/1118.ann    \n","  inflating: Collection5/1118.txt    \n","  inflating: Collection5/1119.ann    \n","  inflating: Collection5/1119.txt    \n","  inflating: Collection5/112.ann     \n","  inflating: Collection5/112.txt     \n","  inflating: Collection5/1120.ann    \n","  inflating: Collection5/1120.txt    \n","  inflating: Collection5/1121.ann    \n","  inflating: Collection5/1121.txt    \n","  inflating: Collection5/1122.ann    \n","  inflating: Collection5/1122.txt    \n","  inflating: Collection5/1123.ann    \n","  inflating: Collection5/1123.txt    \n","  inflating: Collection5/1124.ann    \n","  inflating: Collection5/1124.txt    \n","  inflating: Collection5/1125.ann    \n","  inflating: Collection5/1125.txt    \n","  inflating: Collection5/1126.ann    \n","  inflating: Collection5/1126.txt    \n","  inflating: Collection5/1127.ann    \n","  inflating: Collection5/1127.txt    \n","  inflating: Collection5/1128.ann    \n","  inflating: Collection5/1128.txt    \n","  inflating: Collection5/113.ann     \n","  inflating: Collection5/113.txt     \n","  inflating: Collection5/1130.ann    \n","  inflating: Collection5/1130.txt    \n","  inflating: Collection5/1131.ann    \n","  inflating: Collection5/1131.txt    \n","  inflating: Collection5/1132.ann    \n","  inflating: Collection5/1132.txt    \n","  inflating: Collection5/1133.ann    \n","  inflating: Collection5/1133.txt    \n","  inflating: Collection5/1134.ann    \n","  inflating: Collection5/1134.txt    \n","  inflating: Collection5/1135.ann    \n","  inflating: Collection5/1135.txt    \n","  inflating: Collection5/1136.ann    \n","  inflating: Collection5/1136.txt    \n","  inflating: Collection5/1137.ann    \n","  inflating: Collection5/1137.txt    \n","  inflating: Collection5/1138.ann    \n","  inflating: Collection5/1138.txt    \n","  inflating: Collection5/1139.ann    \n","  inflating: Collection5/1139.txt    \n","  inflating: Collection5/114.ann     \n","  inflating: Collection5/114.txt     \n","  inflating: Collection5/1140.ann    \n","  inflating: Collection5/1140.txt    \n","  inflating: Collection5/1141.ann    \n","  inflating: Collection5/1141.txt    \n","  inflating: Collection5/1142.ann    \n","  inflating: Collection5/1142.txt    \n","  inflating: Collection5/1143.ann    \n","  inflating: Collection5/1143.txt    \n","  inflating: Collection5/1144.ann    \n","  inflating: Collection5/1144.txt    \n","  inflating: Collection5/1145.ann    \n","  inflating: Collection5/1145.txt    \n","  inflating: Collection5/1146.ann    \n","  inflating: Collection5/1146.txt    \n","  inflating: Collection5/1147.ann    \n","  inflating: Collection5/1147.txt    \n","  inflating: Collection5/1148.ann    \n","  inflating: Collection5/1148.txt    \n","  inflating: Collection5/1149.ann    \n","  inflating: Collection5/1149.txt    \n","  inflating: Collection5/115.ann     \n","  inflating: Collection5/115.txt     \n","  inflating: Collection5/1150.ann    \n","  inflating: Collection5/1150.txt    \n","  inflating: Collection5/1151.ann    \n","  inflating: Collection5/1151.txt    \n","  inflating: Collection5/1152.ann    \n","  inflating: Collection5/1152.txt    \n","  inflating: Collection5/1153.ann    \n","  inflating: Collection5/1153.txt    \n","  inflating: Collection5/1154.ann    \n","  inflating: Collection5/1154.txt    \n","  inflating: Collection5/1155.ann    \n","  inflating: Collection5/1155.txt    \n","  inflating: Collection5/1156.ann    \n","  inflating: Collection5/1156.txt    \n","  inflating: Collection5/1157.ann    \n","  inflating: Collection5/1157.txt    \n","  inflating: Collection5/1158.ann    \n","  inflating: Collection5/1158.txt    \n","  inflating: Collection5/1159.ann    \n","  inflating: Collection5/1159.txt    \n","  inflating: Collection5/116.ann     \n","  inflating: Collection5/116.txt     \n","  inflating: Collection5/1160.ann    \n","  inflating: Collection5/1160.txt    \n","  inflating: Collection5/1161.ann    \n","  inflating: Collection5/1161.txt    \n","  inflating: Collection5/1162.ann    \n","  inflating: Collection5/1162.txt    \n","  inflating: Collection5/1163.ann    \n","  inflating: Collection5/1163.txt    \n","  inflating: Collection5/1164.ann    \n","  inflating: Collection5/1164.txt    \n","  inflating: Collection5/1165.ann    \n","  inflating: Collection5/1165.txt    \n","  inflating: Collection5/1166.ann    \n","  inflating: Collection5/1166.txt    \n","  inflating: Collection5/1167.ann    \n","  inflating: Collection5/1167.txt    \n","  inflating: Collection5/1168.ann    \n","  inflating: Collection5/1168.txt    \n","  inflating: Collection5/1169.ann    \n","  inflating: Collection5/1169.txt    \n","  inflating: Collection5/117.ann     \n","  inflating: Collection5/117.txt     \n","  inflating: Collection5/1170.ann    \n","  inflating: Collection5/1170.txt    \n","  inflating: Collection5/1171.ann    \n","  inflating: Collection5/1171.txt    \n","  inflating: Collection5/1172.ann    \n","  inflating: Collection5/1172.txt    \n","  inflating: Collection5/1173.ann    \n","  inflating: Collection5/1173.txt    \n","  inflating: Collection5/1174.ann    \n","  inflating: Collection5/1174.txt    \n","  inflating: Collection5/1175.ann    \n","  inflating: Collection5/1175.txt    \n","  inflating: Collection5/1176.ann    \n","  inflating: Collection5/1176.txt    \n","  inflating: Collection5/1177.ann    \n","  inflating: Collection5/1177.txt    \n","  inflating: Collection5/1178.ann    \n","  inflating: Collection5/1178.txt    \n","  inflating: Collection5/1179.ann    \n","  inflating: Collection5/1179.txt    \n","  inflating: Collection5/118.ann     \n","  inflating: Collection5/118.txt     \n","  inflating: Collection5/1180.ann    \n","  inflating: Collection5/1180.txt    \n","  inflating: Collection5/1181.ann    \n","  inflating: Collection5/1181.txt    \n","  inflating: Collection5/1182.ann    \n","  inflating: Collection5/1182.txt    \n","  inflating: Collection5/1183.ann    \n","  inflating: Collection5/1183.txt    \n","  inflating: Collection5/1184.ann    \n","  inflating: Collection5/1184.txt    \n","  inflating: Collection5/1185.ann    \n","  inflating: Collection5/1185.txt    \n","  inflating: Collection5/1186.ann    \n","  inflating: Collection5/1186.txt    \n","  inflating: Collection5/1187.ann    \n","  inflating: Collection5/1187.txt    \n","  inflating: Collection5/1188.ann    \n","  inflating: Collection5/1188.txt    \n","  inflating: Collection5/1189.ann    \n","  inflating: Collection5/1189.txt    \n","  inflating: Collection5/119.ann     \n","  inflating: Collection5/119.txt     \n","  inflating: Collection5/1190.ann    \n","  inflating: Collection5/1190.txt    \n","  inflating: Collection5/1191.ann    \n","  inflating: Collection5/1191.txt    \n","  inflating: Collection5/1192.ann    \n","  inflating: Collection5/1192.txt    \n","  inflating: Collection5/1193.ann    \n","  inflating: Collection5/1193.txt    \n","  inflating: Collection5/1194.ann    \n","  inflating: Collection5/1194.txt    \n","  inflating: Collection5/1195.ann    \n","  inflating: Collection5/1195.txt    \n","  inflating: Collection5/1196.ann    \n","  inflating: Collection5/1196.txt    \n","  inflating: Collection5/1197.ann    \n","  inflating: Collection5/1197.txt    \n","  inflating: Collection5/1198.ann    \n","  inflating: Collection5/1198.txt    \n","  inflating: Collection5/1199.ann    \n","  inflating: Collection5/1199.txt    \n","  inflating: Collection5/11_01_13b.ann  \n","  inflating: Collection5/11_01_13b.txt  \n","  inflating: Collection5/11_01_13e.ann  \n","  inflating: Collection5/11_01_13e.txt  \n","  inflating: Collection5/120.ann     \n","  inflating: Collection5/120.txt     \n","  inflating: Collection5/1200.ann    \n","  inflating: Collection5/1200.txt    \n","  inflating: Collection5/121.ann     \n","  inflating: Collection5/121.txt     \n","  inflating: Collection5/122.ann     \n","  inflating: Collection5/122.txt     \n","  inflating: Collection5/123.ann     \n","  inflating: Collection5/123.txt     \n","  inflating: Collection5/124.ann     \n","  inflating: Collection5/124.txt     \n","  inflating: Collection5/125.ann     \n","  inflating: Collection5/125.txt     \n","  inflating: Collection5/126.ann     \n","  inflating: Collection5/126.txt     \n","  inflating: Collection5/127.ann     \n","  inflating: Collection5/127.txt     \n","  inflating: Collection5/128.ann     \n","  inflating: Collection5/128.txt     \n","  inflating: Collection5/129.ann     \n","  inflating: Collection5/129.txt     \n","  inflating: Collection5/130.ann     \n","  inflating: Collection5/130.txt     \n","  inflating: Collection5/131.ann     \n","  inflating: Collection5/131.txt     \n","  inflating: Collection5/132.ann     \n","  inflating: Collection5/132.txt     \n","  inflating: Collection5/133.ann     \n","  inflating: Collection5/133.txt     \n","  inflating: Collection5/134.ann     \n","  inflating: Collection5/134.txt     \n","  inflating: Collection5/135.ann     \n","  inflating: Collection5/135.txt     \n","  inflating: Collection5/136.ann     \n","  inflating: Collection5/136.txt     \n","  inflating: Collection5/137.ann     \n","  inflating: Collection5/137.txt     \n","  inflating: Collection5/138.ann     \n","  inflating: Collection5/138.txt     \n","  inflating: Collection5/139.ann     \n","  inflating: Collection5/139.txt     \n","  inflating: Collection5/140.ann     \n","  inflating: Collection5/140.txt     \n","  inflating: Collection5/141.ann     \n","  inflating: Collection5/141.txt     \n","  inflating: Collection5/142.ann     \n","  inflating: Collection5/142.txt     \n","  inflating: Collection5/143.ann     \n","  inflating: Collection5/143.txt     \n","  inflating: Collection5/144.ann     \n","  inflating: Collection5/144.txt     \n","  inflating: Collection5/145.ann     \n","  inflating: Collection5/145.txt     \n","  inflating: Collection5/146.ann     \n","  inflating: Collection5/146.txt     \n","  inflating: Collection5/147.ann     \n","  inflating: Collection5/147.txt     \n","  inflating: Collection5/148.ann     \n","  inflating: Collection5/148.txt     \n","  inflating: Collection5/149.ann     \n","  inflating: Collection5/149.txt     \n","  inflating: Collection5/14_01_13c.ann  \n","  inflating: Collection5/14_01_13c.txt  \n","  inflating: Collection5/14_01_13g.ann  \n","  inflating: Collection5/14_01_13g.txt  \n","  inflating: Collection5/14_01_13i.ann  \n","  inflating: Collection5/14_01_13i.txt  \n","  inflating: Collection5/150.ann     \n","  inflating: Collection5/150.txt     \n","  inflating: Collection5/151.ann     \n","  inflating: Collection5/151.txt     \n","  inflating: Collection5/152.ann     \n","  inflating: Collection5/152.txt     \n","  inflating: Collection5/153.ann     \n","  inflating: Collection5/153.txt     \n","  inflating: Collection5/154.ann     \n","  inflating: Collection5/154.txt     \n","  inflating: Collection5/155.ann     \n","  inflating: Collection5/155.txt     \n","  inflating: Collection5/156.ann     \n","  inflating: Collection5/156.txt     \n","  inflating: Collection5/157.ann     \n","  inflating: Collection5/157.txt     \n","  inflating: Collection5/158.ann     \n","  inflating: Collection5/158.txt     \n","  inflating: Collection5/159.ann     \n","  inflating: Collection5/159.txt     \n","  inflating: Collection5/15_01_13a.ann  \n","  inflating: Collection5/15_01_13a.txt  \n","  inflating: Collection5/15_01_13b.ann  \n","  inflating: Collection5/15_01_13b.txt  \n","  inflating: Collection5/15_01_13e.ann  \n","  inflating: Collection5/15_01_13e.txt  \n","  inflating: Collection5/15_01_13f.ann  \n","  inflating: Collection5/15_01_13f.txt  \n","  inflating: Collection5/160.ann     \n","  inflating: Collection5/160.txt     \n","  inflating: Collection5/161.ann     \n","  inflating: Collection5/161.txt     \n","  inflating: Collection5/162.ann     \n","  inflating: Collection5/162.txt     \n","  inflating: Collection5/163.ann     \n","  inflating: Collection5/163.txt     \n","  inflating: Collection5/164.ann     \n","  inflating: Collection5/164.txt     \n","  inflating: Collection5/165.ann     \n","  inflating: Collection5/165.txt     \n","  inflating: Collection5/166.ann     \n","  inflating: Collection5/166.txt     \n","  inflating: Collection5/167.ann     \n","  inflating: Collection5/167.txt     \n","  inflating: Collection5/168.ann     \n","  inflating: Collection5/168.txt     \n","  inflating: Collection5/169.ann     \n","  inflating: Collection5/169.txt     \n","  inflating: Collection5/170.ann     \n","  inflating: Collection5/170.txt     \n","  inflating: Collection5/171.ann     \n","  inflating: Collection5/171.txt     \n","  inflating: Collection5/172.ann     \n","  inflating: Collection5/172.txt     \n","  inflating: Collection5/173.ann     \n","  inflating: Collection5/173.txt     \n","  inflating: Collection5/174.ann     \n","  inflating: Collection5/174.txt     \n","  inflating: Collection5/175.ann     \n","  inflating: Collection5/175.txt     \n","  inflating: Collection5/176.ann     \n","  inflating: Collection5/176.txt     \n","  inflating: Collection5/177.ann     \n","  inflating: Collection5/177.txt     \n","  inflating: Collection5/178.ann     \n","  inflating: Collection5/178.txt     \n","  inflating: Collection5/179.ann     \n","  inflating: Collection5/179.txt     \n","  inflating: Collection5/180.ann     \n","  inflating: Collection5/180.txt     \n","  inflating: Collection5/181.ann     \n","  inflating: Collection5/181.txt     \n","  inflating: Collection5/182.ann     \n","  inflating: Collection5/182.txt     \n","  inflating: Collection5/183.ann     \n","  inflating: Collection5/183.txt     \n","  inflating: Collection5/184.ann     \n","  inflating: Collection5/184.txt     \n","  inflating: Collection5/185.ann     \n","  inflating: Collection5/185.txt     \n","  inflating: Collection5/186.ann     \n","  inflating: Collection5/186.txt     \n","  inflating: Collection5/187.ann     \n","  inflating: Collection5/187.txt     \n","  inflating: Collection5/188.ann     \n","  inflating: Collection5/188.txt     \n","  inflating: Collection5/189.ann     \n","  inflating: Collection5/189.txt     \n","  inflating: Collection5/190.ann     \n","  inflating: Collection5/190.txt     \n","  inflating: Collection5/191.ann     \n","  inflating: Collection5/191.txt     \n","  inflating: Collection5/192.ann     \n","  inflating: Collection5/192.txt     \n","  inflating: Collection5/193.ann     \n","  inflating: Collection5/193.txt     \n","  inflating: Collection5/194.ann     \n","  inflating: Collection5/194.txt     \n","  inflating: Collection5/195.ann     \n","  inflating: Collection5/195.txt     \n","  inflating: Collection5/196.ann     \n","  inflating: Collection5/196.txt     \n","  inflating: Collection5/197.ann     \n","  inflating: Collection5/197.txt     \n","  inflating: Collection5/198.ann     \n","  inflating: Collection5/198.txt     \n","  inflating: Collection5/199.ann     \n","  inflating: Collection5/199.txt     \n","  inflating: Collection5/19_11_12d.ann  \n","  inflating: Collection5/19_11_12d.txt  \n","  inflating: Collection5/19_11_12h.ann  \n","  inflating: Collection5/19_11_12h.txt  \n","  inflating: Collection5/200.ann     \n","  inflating: Collection5/200.txt     \n","  inflating: Collection5/2001.ann    \n","  inflating: Collection5/2001.txt    \n","  inflating: Collection5/2002.ann    \n","  inflating: Collection5/2002.txt    \n","  inflating: Collection5/2003.ann    \n","  inflating: Collection5/2003.txt    \n","  inflating: Collection5/2004.ann    \n","  inflating: Collection5/2004.txt    \n","  inflating: Collection5/2005.ann    \n","  inflating: Collection5/2005.txt    \n","  inflating: Collection5/2006.ann    \n","  inflating: Collection5/2006.txt    \n","  inflating: Collection5/2007.ann    \n","  inflating: Collection5/2007.txt    \n","  inflating: Collection5/2008.ann    \n","  inflating: Collection5/2008.txt    \n","  inflating: Collection5/2009.ann    \n","  inflating: Collection5/2009.txt    \n","  inflating: Collection5/201.ann     \n","  inflating: Collection5/201.txt     \n","  inflating: Collection5/2010.ann    \n","  inflating: Collection5/2010.txt    \n","  inflating: Collection5/2011.ann    \n","  inflating: Collection5/2011.txt    \n","  inflating: Collection5/2012.ann    \n","  inflating: Collection5/2012.txt    \n","  inflating: Collection5/2013.ann    \n","  inflating: Collection5/2013.txt    \n","  inflating: Collection5/2014.ann    \n","  inflating: Collection5/2014.txt    \n","  inflating: Collection5/2015.ann    \n","  inflating: Collection5/2015.txt    \n","  inflating: Collection5/2016.ann    \n","  inflating: Collection5/2016.txt    \n","  inflating: Collection5/2017.ann    \n","  inflating: Collection5/2017.txt    \n","  inflating: Collection5/2018.ann    \n","  inflating: Collection5/2018.txt    \n","  inflating: Collection5/2019.ann    \n","  inflating: Collection5/2019.txt    \n","  inflating: Collection5/202.ann     \n","  inflating: Collection5/202.txt     \n","  inflating: Collection5/2020.ann    \n","  inflating: Collection5/2020.txt    \n","  inflating: Collection5/2021.ann    \n","  inflating: Collection5/2021.txt    \n","  inflating: Collection5/2022.ann    \n","  inflating: Collection5/2022.txt    \n","  inflating: Collection5/2023.ann    \n","  inflating: Collection5/2023.txt    \n","  inflating: Collection5/2024.ann    \n","  inflating: Collection5/2024.txt    \n","  inflating: Collection5/2025.ann    \n","  inflating: Collection5/2025.txt    \n","  inflating: Collection5/2026.ann    \n","  inflating: Collection5/2026.txt    \n","  inflating: Collection5/2027.ann    \n","  inflating: Collection5/2027.txt    \n","  inflating: Collection5/2028.ann    \n","  inflating: Collection5/2028.txt    \n","  inflating: Collection5/2029.ann    \n","  inflating: Collection5/2029.txt    \n","  inflating: Collection5/203.ann     \n","  inflating: Collection5/203.txt     \n","  inflating: Collection5/2030.ann    \n","  inflating: Collection5/2030.txt    \n","  inflating: Collection5/2031.ann    \n","  inflating: Collection5/2031.txt    \n","  inflating: Collection5/2032.ann    \n","  inflating: Collection5/2032.txt    \n","  inflating: Collection5/2034.ann    \n","  inflating: Collection5/2034.txt    \n","  inflating: Collection5/2035.ann    \n","  inflating: Collection5/2035.txt    \n","  inflating: Collection5/2036.ann    \n","  inflating: Collection5/2036.txt    \n","  inflating: Collection5/2037.ann    \n","  inflating: Collection5/2037.txt    \n","  inflating: Collection5/2038.ann    \n","  inflating: Collection5/2038.txt    \n","  inflating: Collection5/2039.ann    \n","  inflating: Collection5/2039.txt    \n","  inflating: Collection5/204.ann     \n","  inflating: Collection5/204.txt     \n","  inflating: Collection5/2040.ann    \n","  inflating: Collection5/2040.txt    \n","  inflating: Collection5/2041.ann    \n","  inflating: Collection5/2041.txt    \n","  inflating: Collection5/2042.ann    \n","  inflating: Collection5/2042.txt    \n","  inflating: Collection5/2043.ann    \n","  inflating: Collection5/2043.txt    \n","  inflating: Collection5/2044.ann    \n","  inflating: Collection5/2044.txt    \n","  inflating: Collection5/2045.ann    \n","  inflating: Collection5/2045.txt    \n","  inflating: Collection5/2046.ann    \n","  inflating: Collection5/2046.txt    \n","  inflating: Collection5/2047.ann    \n","  inflating: Collection5/2047.txt    \n","  inflating: Collection5/2048.ann    \n","  inflating: Collection5/2048.txt    \n","  inflating: Collection5/2049.ann    \n","  inflating: Collection5/2049.txt    \n","  inflating: Collection5/205.ann     \n","  inflating: Collection5/205.txt     \n","  inflating: Collection5/2050.ann    \n","  inflating: Collection5/2050.txt    \n","  inflating: Collection5/206.ann     \n","  inflating: Collection5/206.txt     \n","  inflating: Collection5/207.ann     \n","  inflating: Collection5/207.txt     \n","  inflating: Collection5/208.ann     \n","  inflating: Collection5/208.txt     \n","  inflating: Collection5/209.ann     \n","  inflating: Collection5/209.txt     \n","  inflating: Collection5/20_11_12a.ann  \n","  inflating: Collection5/20_11_12a.txt  \n","  inflating: Collection5/20_11_12b.ann  \n","  inflating: Collection5/20_11_12b.txt  \n","  inflating: Collection5/20_11_12c.ann  \n","  inflating: Collection5/20_11_12c.txt  \n","  inflating: Collection5/20_11_12d.ann  \n","  inflating: Collection5/20_11_12d.txt  \n","  inflating: Collection5/20_11_12i.ann  \n","  inflating: Collection5/20_11_12i.txt  \n","  inflating: Collection5/210.ann     \n","  inflating: Collection5/210.txt     \n","  inflating: Collection5/211.ann     \n","  inflating: Collection5/211.txt     \n","  inflating: Collection5/212.ann     \n","  inflating: Collection5/212.txt     \n","  inflating: Collection5/213.ann     \n","  inflating: Collection5/213.txt     \n","  inflating: Collection5/214.ann     \n","  inflating: Collection5/214.txt     \n","  inflating: Collection5/215.ann     \n","  inflating: Collection5/215.txt     \n","  inflating: Collection5/216.ann     \n","  inflating: Collection5/216.txt     \n","  inflating: Collection5/217.ann     \n","  inflating: Collection5/217.txt     \n","  inflating: Collection5/218.ann     \n","  inflating: Collection5/218.txt     \n","  inflating: Collection5/219.ann     \n","  inflating: Collection5/219.txt     \n","  inflating: Collection5/21_11_12c.ann  \n","  inflating: Collection5/21_11_12c.txt  \n","  inflating: Collection5/21_11_12h.ann  \n","  inflating: Collection5/21_11_12h.txt  \n","  inflating: Collection5/21_11_12i.ann  \n","  inflating: Collection5/21_11_12i.txt  \n","  inflating: Collection5/21_11_12j.ann  \n","  inflating: Collection5/21_11_12j.txt  \n","  inflating: Collection5/220.ann     \n","  inflating: Collection5/220.txt     \n","  inflating: Collection5/221.ann     \n","  inflating: Collection5/221.txt     \n","  inflating: Collection5/222.ann     \n","  inflating: Collection5/222.txt     \n","  inflating: Collection5/223.ann     \n","  inflating: Collection5/223.txt     \n","  inflating: Collection5/224.ann     \n","  inflating: Collection5/224.txt     \n","  inflating: Collection5/225.ann     \n","  inflating: Collection5/225.txt     \n","  inflating: Collection5/226.ann     \n","  inflating: Collection5/226.txt     \n","  inflating: Collection5/227.ann     \n","  inflating: Collection5/227.txt     \n","  inflating: Collection5/228.ann     \n","  inflating: Collection5/228.txt     \n","  inflating: Collection5/229.ann     \n","  inflating: Collection5/229.txt     \n","  inflating: Collection5/22_11_12a.ann  \n","  inflating: Collection5/22_11_12a.txt  \n","  inflating: Collection5/22_11_12c.ann  \n","  inflating: Collection5/22_11_12c.txt  \n","  inflating: Collection5/22_11_12d.ann  \n","  inflating: Collection5/22_11_12d.txt  \n","  inflating: Collection5/22_11_12g.ann  \n","  inflating: Collection5/22_11_12g.txt  \n","  inflating: Collection5/22_11_12h.ann  \n","  inflating: Collection5/22_11_12h.txt  \n","  inflating: Collection5/22_11_12i.ann  \n","  inflating: Collection5/22_11_12i.txt  \n","  inflating: Collection5/22_11_12j.ann  \n","  inflating: Collection5/22_11_12j.txt  \n","  inflating: Collection5/230.ann     \n","  inflating: Collection5/230.txt     \n","  inflating: Collection5/231.ann     \n","  inflating: Collection5/231.txt     \n","  inflating: Collection5/232.ann     \n","  inflating: Collection5/232.txt     \n","  inflating: Collection5/233.ann     \n","  inflating: Collection5/233.txt     \n","  inflating: Collection5/234.ann     \n","  inflating: Collection5/234.txt     \n","  inflating: Collection5/235.ann     \n","  inflating: Collection5/235.txt     \n","  inflating: Collection5/236.ann     \n","  inflating: Collection5/236.txt     \n","  inflating: Collection5/237.ann     \n","  inflating: Collection5/237.txt     \n","  inflating: Collection5/238.ann     \n","  inflating: Collection5/238.txt     \n","  inflating: Collection5/239.ann     \n","  inflating: Collection5/239.txt     \n","  inflating: Collection5/23_11_12a.ann  \n","  inflating: Collection5/23_11_12a.txt  \n","  inflating: Collection5/23_11_12b.ann  \n","  inflating: Collection5/23_11_12b.txt  \n","  inflating: Collection5/23_11_12c.ann  \n","  inflating: Collection5/23_11_12c.txt  \n","  inflating: Collection5/23_11_12d.ann  \n","  inflating: Collection5/23_11_12d.txt  \n","  inflating: Collection5/23_11_12e.ann  \n","  inflating: Collection5/23_11_12e.txt  \n","  inflating: Collection5/23_11_12f.ann  \n","  inflating: Collection5/23_11_12f.txt  \n","  inflating: Collection5/240.ann     \n","  inflating: Collection5/240.txt     \n","  inflating: Collection5/241.ann     \n","  inflating: Collection5/241.txt     \n","  inflating: Collection5/242.ann     \n","  inflating: Collection5/242.txt     \n","  inflating: Collection5/243.ann     \n","  inflating: Collection5/243.txt     \n","  inflating: Collection5/244.ann     \n","  inflating: Collection5/244.txt     \n","  inflating: Collection5/245.ann     \n","  inflating: Collection5/245.txt     \n","  inflating: Collection5/246.ann     \n","  inflating: Collection5/246.txt     \n","  inflating: Collection5/247.ann     \n","  inflating: Collection5/247.txt     \n","  inflating: Collection5/248.ann     \n","  inflating: Collection5/248.txt     \n","  inflating: Collection5/249.ann     \n","  inflating: Collection5/249.txt     \n","  inflating: Collection5/250.ann     \n","  inflating: Collection5/250.txt     \n","  inflating: Collection5/251.ann     \n","  inflating: Collection5/251.txt     \n","  inflating: Collection5/252.ann     \n","  inflating: Collection5/252.txt     \n","  inflating: Collection5/253.ann     \n","  inflating: Collection5/253.txt     \n","  inflating: Collection5/254.ann     \n","  inflating: Collection5/254.txt     \n","  inflating: Collection5/255.ann     \n","  inflating: Collection5/255.txt     \n","  inflating: Collection5/256.ann     \n","  inflating: Collection5/256.txt     \n","  inflating: Collection5/257.ann     \n","  inflating: Collection5/257.txt     \n","  inflating: Collection5/258.ann     \n","  inflating: Collection5/258.txt     \n","  inflating: Collection5/259.ann     \n","  inflating: Collection5/259.txt     \n","  inflating: Collection5/25_12_12a.ann  \n","  inflating: Collection5/25_12_12a.txt  \n","  inflating: Collection5/25_12_12c.ann  \n","  inflating: Collection5/25_12_12c.txt  \n","  inflating: Collection5/25_12_12d.ann  \n","  inflating: Collection5/25_12_12d.txt  \n","  inflating: Collection5/25_12_12e.ann  \n","  inflating: Collection5/25_12_12e.txt  \n","  inflating: Collection5/260.ann     \n","  inflating: Collection5/260.txt     \n","  inflating: Collection5/261.ann     \n","  inflating: Collection5/261.txt     \n","  inflating: Collection5/262.ann     \n","  inflating: Collection5/262.txt     \n","  inflating: Collection5/263.ann     \n","  inflating: Collection5/263.txt     \n","  inflating: Collection5/264.ann     \n","  inflating: Collection5/264.txt     \n","  inflating: Collection5/265.ann     \n","  inflating: Collection5/265.txt     \n","  inflating: Collection5/266.ann     \n","  inflating: Collection5/266.txt     \n","  inflating: Collection5/267.ann     \n","  inflating: Collection5/267.txt     \n","  inflating: Collection5/268.ann     \n","  inflating: Collection5/268.txt     \n","  inflating: Collection5/269.ann     \n","  inflating: Collection5/269.txt     \n","  inflating: Collection5/26_11_12b.ann  \n","  inflating: Collection5/26_11_12b.txt  \n","  inflating: Collection5/26_11_12c.ann  \n","  inflating: Collection5/26_11_12c.txt  \n","  inflating: Collection5/26_11_12e.ann  \n","  inflating: Collection5/26_11_12e.txt  \n","  inflating: Collection5/26_11_12f.ann  \n","  inflating: Collection5/26_11_12f.txt  \n","  inflating: Collection5/270.ann     \n","  inflating: Collection5/270.txt     \n","  inflating: Collection5/271.ann     \n","  inflating: Collection5/271.txt     \n","  inflating: Collection5/272.ann     \n","  inflating: Collection5/272.txt     \n","  inflating: Collection5/273.ann     \n","  inflating: Collection5/273.txt     \n","  inflating: Collection5/274.ann     \n","  inflating: Collection5/274.txt     \n","  inflating: Collection5/275.ann     \n","  inflating: Collection5/275.txt     \n","  inflating: Collection5/276.ann     \n","  inflating: Collection5/276.txt     \n","  inflating: Collection5/277.ann     \n","  inflating: Collection5/277.txt     \n","  inflating: Collection5/278.ann     \n","  inflating: Collection5/278.txt     \n","  inflating: Collection5/279.ann     \n","  inflating: Collection5/279.txt     \n","  inflating: Collection5/27_11_12a.ann  \n","  inflating: Collection5/27_11_12a.txt  \n","  inflating: Collection5/27_11_12c.ann  \n","  inflating: Collection5/27_11_12c.txt  \n","  inflating: Collection5/27_11_12d.ann  \n","  inflating: Collection5/27_11_12d.txt  \n","  inflating: Collection5/27_11_12e.ann  \n","  inflating: Collection5/27_11_12e.txt  \n","  inflating: Collection5/27_11_12j.ann  \n","  inflating: Collection5/27_11_12j.txt  \n","  inflating: Collection5/280.ann     \n","  inflating: Collection5/280.txt     \n","  inflating: Collection5/281.ann     \n","  inflating: Collection5/281.txt     \n","  inflating: Collection5/282.ann     \n","  inflating: Collection5/282.txt     \n","  inflating: Collection5/283.ann     \n","  inflating: Collection5/283.txt     \n","  inflating: Collection5/284.ann     \n","  inflating: Collection5/284.txt     \n","  inflating: Collection5/285.ann     \n","  inflating: Collection5/285.txt     \n","  inflating: Collection5/286.ann     \n","  inflating: Collection5/286.txt     \n","  inflating: Collection5/287.ann     \n","  inflating: Collection5/287.txt     \n","  inflating: Collection5/288.ann     \n","  inflating: Collection5/288.txt     \n","  inflating: Collection5/289.ann     \n","  inflating: Collection5/289.txt     \n","  inflating: Collection5/28_11_12a.ann  \n","  inflating: Collection5/28_11_12a.txt  \n","  inflating: Collection5/28_11_12f.ann  \n","  inflating: Collection5/28_11_12f.txt  \n","  inflating: Collection5/28_11_12g.ann  \n","  inflating: Collection5/28_11_12g.txt  \n","  inflating: Collection5/28_11_12h.ann  \n","  inflating: Collection5/28_11_12h.txt  \n","  inflating: Collection5/28_11_12i.ann  \n","  inflating: Collection5/28_11_12i.txt  \n","  inflating: Collection5/28_11_12j.ann  \n","  inflating: Collection5/28_11_12j.txt  \n","  inflating: Collection5/290.ann     \n","  inflating: Collection5/290.txt     \n","  inflating: Collection5/291.ann     \n","  inflating: Collection5/291.txt     \n","  inflating: Collection5/292.ann     \n","  inflating: Collection5/292.txt     \n","  inflating: Collection5/293.ann     \n","  inflating: Collection5/293.txt     \n","  inflating: Collection5/294.ann     \n","  inflating: Collection5/294.txt     \n","  inflating: Collection5/295.ann     \n","  inflating: Collection5/295.txt     \n","  inflating: Collection5/296.ann     \n","  inflating: Collection5/296.txt     \n","  inflating: Collection5/297.ann     \n","  inflating: Collection5/297.txt     \n","  inflating: Collection5/298.ann     \n","  inflating: Collection5/298.txt     \n","  inflating: Collection5/299.ann     \n","  inflating: Collection5/299.txt     \n","  inflating: Collection5/29_11_12a.ann  \n","  inflating: Collection5/29_11_12a.txt  \n","  inflating: Collection5/29_11_12b.ann  \n","  inflating: Collection5/29_11_12b.txt  \n","  inflating: Collection5/300.ann     \n","  inflating: Collection5/300.txt     \n","  inflating: Collection5/301.ann     \n","  inflating: Collection5/301.txt     \n","  inflating: Collection5/302.ann     \n","  inflating: Collection5/302.txt     \n","  inflating: Collection5/303.ann     \n","  inflating: Collection5/303.txt     \n","  inflating: Collection5/304.ann     \n","  inflating: Collection5/304.txt     \n","  inflating: Collection5/305.ann     \n","  inflating: Collection5/305.txt     \n","  inflating: Collection5/306.ann     \n","  inflating: Collection5/306.txt     \n","  inflating: Collection5/307.ann     \n","  inflating: Collection5/307.txt     \n","  inflating: Collection5/308.ann     \n","  inflating: Collection5/308.txt     \n","  inflating: Collection5/309.ann     \n","  inflating: Collection5/309.txt     \n","  inflating: Collection5/30_11_12b.ann  \n","  inflating: Collection5/30_11_12b.txt  \n","  inflating: Collection5/30_11_12h.ann  \n","  inflating: Collection5/30_11_12h.txt  \n","  inflating: Collection5/30_11_12i.ann  \n","  inflating: Collection5/30_11_12i.txt  \n","  inflating: Collection5/310.ann     \n","  inflating: Collection5/310.txt     \n","  inflating: Collection5/311.ann     \n","  inflating: Collection5/311.txt     \n","  inflating: Collection5/312.ann     \n","  inflating: Collection5/312.txt     \n","  inflating: Collection5/313.ann     \n","  inflating: Collection5/313.txt     \n","  inflating: Collection5/314.ann     \n","  inflating: Collection5/314.txt     \n","  inflating: Collection5/315.ann     \n","  inflating: Collection5/315.txt     \n","  inflating: Collection5/316.ann     \n","  inflating: Collection5/316.txt     \n","  inflating: Collection5/317.ann     \n","  inflating: Collection5/317.txt     \n","  inflating: Collection5/318.ann     \n","  inflating: Collection5/318.txt     \n","  inflating: Collection5/319.ann     \n","  inflating: Collection5/319.txt     \n","  inflating: Collection5/320.ann     \n","  inflating: Collection5/320.txt     \n","  inflating: Collection5/321.ann     \n","  inflating: Collection5/321.txt     \n","  inflating: Collection5/322.ann     \n","  inflating: Collection5/322.txt     \n","  inflating: Collection5/323.ann     \n","  inflating: Collection5/323.txt     \n","  inflating: Collection5/324.ann     \n","  inflating: Collection5/324.txt     \n","  inflating: Collection5/325.ann     \n","  inflating: Collection5/325.txt     \n","  inflating: Collection5/326.ann     \n","  inflating: Collection5/326.txt     \n","  inflating: Collection5/327.ann     \n","  inflating: Collection5/327.txt     \n","  inflating: Collection5/328.ann     \n","  inflating: Collection5/328.txt     \n","  inflating: Collection5/329.ann     \n","  inflating: Collection5/329.txt     \n","  inflating: Collection5/330.ann     \n","  inflating: Collection5/330.txt     \n","  inflating: Collection5/331.ann     \n","  inflating: Collection5/331.txt     \n","  inflating: Collection5/332.ann     \n","  inflating: Collection5/332.txt     \n","  inflating: Collection5/333.ann     \n","  inflating: Collection5/333.txt     \n","  inflating: Collection5/334.ann     \n","  inflating: Collection5/334.txt     \n","  inflating: Collection5/335.ann     \n","  inflating: Collection5/335.txt     \n","  inflating: Collection5/336.ann     \n","  inflating: Collection5/336.txt     \n","  inflating: Collection5/337.ann     \n","  inflating: Collection5/337.txt     \n","  inflating: Collection5/338.ann     \n","  inflating: Collection5/338.txt     \n","  inflating: Collection5/339.ann     \n","  inflating: Collection5/339.txt     \n","  inflating: Collection5/340.ann     \n","  inflating: Collection5/340.txt     \n","  inflating: Collection5/341.ann     \n","  inflating: Collection5/341.txt     \n","  inflating: Collection5/342.ann     \n","  inflating: Collection5/342.txt     \n","  inflating: Collection5/343.ann     \n","  inflating: Collection5/343.txt     \n","  inflating: Collection5/344.ann     \n","  inflating: Collection5/344.txt     \n","  inflating: Collection5/345.ann     \n","  inflating: Collection5/345.txt     \n","  inflating: Collection5/346.ann     \n","  inflating: Collection5/346.txt     \n","  inflating: Collection5/347.ann     \n","  inflating: Collection5/347.txt     \n","  inflating: Collection5/348.ann     \n","  inflating: Collection5/348.txt     \n","  inflating: Collection5/349.ann     \n","  inflating: Collection5/349.txt     \n","  inflating: Collection5/350.ann     \n","  inflating: Collection5/350.txt     \n","  inflating: Collection5/351.ann     \n","  inflating: Collection5/351.txt     \n","  inflating: Collection5/352.ann     \n","  inflating: Collection5/352.txt     \n","  inflating: Collection5/353.ann     \n","  inflating: Collection5/353.txt     \n","  inflating: Collection5/354.ann     \n","  inflating: Collection5/354.txt     \n","  inflating: Collection5/355.ann     \n","  inflating: Collection5/355.txt     \n","  inflating: Collection5/356.ann     \n","  inflating: Collection5/356.txt     \n","  inflating: Collection5/357.ann     \n","  inflating: Collection5/357.txt     \n","  inflating: Collection5/358.ann     \n","  inflating: Collection5/358.txt     \n","  inflating: Collection5/359.ann     \n","  inflating: Collection5/359.txt     \n","  inflating: Collection5/360.ann     \n","  inflating: Collection5/360.txt     \n","  inflating: Collection5/361.ann     \n","  inflating: Collection5/361.txt     \n","  inflating: Collection5/362.ann     \n","  inflating: Collection5/362.txt     \n","  inflating: Collection5/363.ann     \n","  inflating: Collection5/363.txt     \n","  inflating: Collection5/364.ann     \n","  inflating: Collection5/364.txt     \n","  inflating: Collection5/365.ann     \n","  inflating: Collection5/365.txt     \n","  inflating: Collection5/366.ann     \n","  inflating: Collection5/366.txt     \n","  inflating: Collection5/367.ann     \n","  inflating: Collection5/367.txt     \n","  inflating: Collection5/368.ann     \n","  inflating: Collection5/368.txt     \n","  inflating: Collection5/369.ann     \n","  inflating: Collection5/369.txt     \n","  inflating: Collection5/370.ann     \n","  inflating: Collection5/370.txt     \n","  inflating: Collection5/371.ann     \n","  inflating: Collection5/371.txt     \n","  inflating: Collection5/372.ann     \n","  inflating: Collection5/372.txt     \n","  inflating: Collection5/373.ann     \n","  inflating: Collection5/373.txt     \n","  inflating: Collection5/374.ann     \n","  inflating: Collection5/374.txt     \n","  inflating: Collection5/375.ann     \n","  inflating: Collection5/375.txt     \n","  inflating: Collection5/376.ann     \n","  inflating: Collection5/376.txt     \n","  inflating: Collection5/377.ann     \n","  inflating: Collection5/377.txt     \n","  inflating: Collection5/378.ann     \n","  inflating: Collection5/378.txt     \n","  inflating: Collection5/379.ann     \n","  inflating: Collection5/379.txt     \n","  inflating: Collection5/380.ann     \n","  inflating: Collection5/380.txt     \n","  inflating: Collection5/381.ann     \n","  inflating: Collection5/381.txt     \n","  inflating: Collection5/382.ann     \n","  inflating: Collection5/382.txt     \n","  inflating: Collection5/383.ann     \n","  inflating: Collection5/383.txt     \n","  inflating: Collection5/384.ann     \n","  inflating: Collection5/384.txt     \n","  inflating: Collection5/385.ann     \n","  inflating: Collection5/385.txt     \n","  inflating: Collection5/386.ann     \n","  inflating: Collection5/386.txt     \n","  inflating: Collection5/387.ann     \n","  inflating: Collection5/387.txt     \n","  inflating: Collection5/388.ann     \n","  inflating: Collection5/388.txt     \n","  inflating: Collection5/389.ann     \n","  inflating: Collection5/389.txt     \n","  inflating: Collection5/390.ann     \n","  inflating: Collection5/390.txt     \n","  inflating: Collection5/391.ann     \n","  inflating: Collection5/391.txt     \n","  inflating: Collection5/392.ann     \n","  inflating: Collection5/392.txt     \n","  inflating: Collection5/393.ann     \n","  inflating: Collection5/393.txt     \n","  inflating: Collection5/394.ann     \n","  inflating: Collection5/394.txt     \n","  inflating: Collection5/395.ann     \n","  inflating: Collection5/395.txt     \n","  inflating: Collection5/396.ann     \n","  inflating: Collection5/396.txt     \n","  inflating: Collection5/397.ann     \n","  inflating: Collection5/397.txt     \n","  inflating: Collection5/398.ann     \n","  inflating: Collection5/398.txt     \n","  inflating: Collection5/399.ann     \n","  inflating: Collection5/399.txt     \n","  inflating: Collection5/400.ann     \n","  inflating: Collection5/400.txt     \n","  inflating: Collection5/401.ann     \n","  inflating: Collection5/401.txt     \n","  inflating: Collection5/402.ann     \n","  inflating: Collection5/402.txt     \n","  inflating: Collection5/403.ann     \n","  inflating: Collection5/403.txt     \n","  inflating: Collection5/404.ann     \n","  inflating: Collection5/404.txt     \n","  inflating: Collection5/405.ann     \n","  inflating: Collection5/405.txt     \n","  inflating: Collection5/406.ann     \n","  inflating: Collection5/406.txt     \n","  inflating: Collection5/407.ann     \n","  inflating: Collection5/407.txt     \n","  inflating: Collection5/408.ann     \n","  inflating: Collection5/408.txt     \n","  inflating: Collection5/409.ann     \n","  inflating: Collection5/409.txt     \n","  inflating: Collection5/410.ann     \n","  inflating: Collection5/410.txt     \n","  inflating: Collection5/411.ann     \n","  inflating: Collection5/411.txt     \n","  inflating: Collection5/412.ann     \n","  inflating: Collection5/412.txt     \n","  inflating: Collection5/413.ann     \n","  inflating: Collection5/413.txt     \n","  inflating: Collection5/414.ann     \n","  inflating: Collection5/414.txt     \n","  inflating: Collection5/415.ann     \n","  inflating: Collection5/415.txt     \n","  inflating: Collection5/416.ann     \n","  inflating: Collection5/416.txt     \n","  inflating: Collection5/417.ann     \n","  inflating: Collection5/417.txt     \n","  inflating: Collection5/418.ann     \n","  inflating: Collection5/418.txt     \n","  inflating: Collection5/419.ann     \n","  inflating: Collection5/419.txt     \n","  inflating: Collection5/420.ann     \n","  inflating: Collection5/420.txt     \n","  inflating: Collection5/421.ann     \n","  inflating: Collection5/421.txt     \n","  inflating: Collection5/422.ann     \n","  inflating: Collection5/422.txt     \n","  inflating: Collection5/423.ann     \n","  inflating: Collection5/423.txt     \n","  inflating: Collection5/424.ann     \n","  inflating: Collection5/424.txt     \n","  inflating: Collection5/425.ann     \n","  inflating: Collection5/425.txt     \n","  inflating: Collection5/426.ann     \n","  inflating: Collection5/426.txt     \n","  inflating: Collection5/427.ann     \n","  inflating: Collection5/427.txt     \n","  inflating: Collection5/428.ann     \n","  inflating: Collection5/428.txt     \n","  inflating: Collection5/429.ann     \n","  inflating: Collection5/429.txt     \n","  inflating: Collection5/430.ann     \n","  inflating: Collection5/430.txt     \n","  inflating: Collection5/431.ann     \n","  inflating: Collection5/431.txt     \n","  inflating: Collection5/432.ann     \n","  inflating: Collection5/432.txt     \n","  inflating: Collection5/433.ann     \n","  inflating: Collection5/433.txt     \n","  inflating: Collection5/434.ann     \n","  inflating: Collection5/434.txt     \n","  inflating: Collection5/435.ann     \n","  inflating: Collection5/435.txt     \n","  inflating: Collection5/436.ann     \n","  inflating: Collection5/436.txt     \n","  inflating: Collection5/437.ann     \n","  inflating: Collection5/437.txt     \n","  inflating: Collection5/438.ann     \n","  inflating: Collection5/438.txt     \n","  inflating: Collection5/439.ann     \n","  inflating: Collection5/439.txt     \n","  inflating: Collection5/440.ann     \n","  inflating: Collection5/440.txt     \n","  inflating: Collection5/441.ann     \n","  inflating: Collection5/441.txt     \n","  inflating: Collection5/442.ann     \n","  inflating: Collection5/442.txt     \n","  inflating: Collection5/443.ann     \n","  inflating: Collection5/443.txt     \n","  inflating: Collection5/444.ann     \n","  inflating: Collection5/444.txt     \n","  inflating: Collection5/445.ann     \n","  inflating: Collection5/445.txt     \n","  inflating: Collection5/446.ann     \n","  inflating: Collection5/446.txt     \n","  inflating: Collection5/447.ann     \n","  inflating: Collection5/447.txt     \n","  inflating: Collection5/448.ann     \n","  inflating: Collection5/448.txt     \n","  inflating: Collection5/449.ann     \n","  inflating: Collection5/449.txt     \n","  inflating: Collection5/450.ann     \n","  inflating: Collection5/450.txt     \n","  inflating: Collection5/451.ann     \n","  inflating: Collection5/451.txt     \n","  inflating: Collection5/452.ann     \n","  inflating: Collection5/452.txt     \n","  inflating: Collection5/453.ann     \n","  inflating: Collection5/453.txt     \n","  inflating: Collection5/454.ann     \n","  inflating: Collection5/454.txt     \n","  inflating: Collection5/455.ann     \n","  inflating: Collection5/455.txt     \n","  inflating: Collection5/457.ann     \n","  inflating: Collection5/457.txt     \n","  inflating: Collection5/458.ann     \n","  inflating: Collection5/458.txt     \n","  inflating: Collection5/459.ann     \n","  inflating: Collection5/459.txt     \n","  inflating: Collection5/460.ann     \n","  inflating: Collection5/460.txt     \n","  inflating: Collection5/461.ann     \n","  inflating: Collection5/461.txt     \n","  inflating: Collection5/462.ann     \n","  inflating: Collection5/462.txt     \n","  inflating: Collection5/463.ann     \n","  inflating: Collection5/463.txt     \n","  inflating: Collection5/464.ann     \n","  inflating: Collection5/464.txt     \n","  inflating: Collection5/465.ann     \n","  inflating: Collection5/465.txt     \n","  inflating: Collection5/466.ann     \n","  inflating: Collection5/466.txt     \n","  inflating: Collection5/467.ann     \n","  inflating: Collection5/467.txt     \n","  inflating: Collection5/468.ann     \n","  inflating: Collection5/468.txt     \n","  inflating: Collection5/469.ann     \n","  inflating: Collection5/469.txt     \n","  inflating: Collection5/470.ann     \n","  inflating: Collection5/470.txt     \n","  inflating: Collection5/471.ann     \n","  inflating: Collection5/471.txt     \n","  inflating: Collection5/472.ann     \n","  inflating: Collection5/472.txt     \n","  inflating: Collection5/473.ann     \n","  inflating: Collection5/473.txt     \n","  inflating: Collection5/474.ann     \n","  inflating: Collection5/474.txt     \n","  inflating: Collection5/475.ann     \n","  inflating: Collection5/475.txt     \n","  inflating: Collection5/476.ann     \n","  inflating: Collection5/476.txt     \n","  inflating: Collection5/477.ann     \n","  inflating: Collection5/477.txt     \n","  inflating: Collection5/478.ann     \n","  inflating: Collection5/478.txt     \n","  inflating: Collection5/479.ann     \n","  inflating: Collection5/479.txt     \n","  inflating: Collection5/480.ann     \n","  inflating: Collection5/480.txt     \n","  inflating: Collection5/481.ann     \n","  inflating: Collection5/481.txt     \n","  inflating: Collection5/482.ann     \n","  inflating: Collection5/482.txt     \n","  inflating: Collection5/483.ann     \n","  inflating: Collection5/483.txt     \n","  inflating: Collection5/484.ann     \n","  inflating: Collection5/484.txt     \n","  inflating: Collection5/485.ann     \n","  inflating: Collection5/485.txt     \n","  inflating: Collection5/486.ann     \n","  inflating: Collection5/486.txt     \n","  inflating: Collection5/487.ann     \n","  inflating: Collection5/487.txt     \n","  inflating: Collection5/488.ann     \n","  inflating: Collection5/488.txt     \n","  inflating: Collection5/489.ann     \n","  inflating: Collection5/489.txt     \n","  inflating: Collection5/490.ann     \n","  inflating: Collection5/490.txt     \n","  inflating: Collection5/491.ann     \n","  inflating: Collection5/491.txt     \n","  inflating: Collection5/492.ann     \n","  inflating: Collection5/492.txt     \n","  inflating: Collection5/493.ann     \n","  inflating: Collection5/493.txt     \n","  inflating: Collection5/494.ann     \n","  inflating: Collection5/494.txt     \n","  inflating: Collection5/495.ann     \n","  inflating: Collection5/495.txt     \n","  inflating: Collection5/496.ann     \n","  inflating: Collection5/496.txt     \n","  inflating: Collection5/497.ann     \n","  inflating: Collection5/497.txt     \n","  inflating: Collection5/498.ann     \n","  inflating: Collection5/498.txt     \n","  inflating: Collection5/499.ann     \n","  inflating: Collection5/499.txt     \n","  inflating: Collection5/500.ann     \n","  inflating: Collection5/500.txt     \n","  inflating: Collection5/501.ann     \n","  inflating: Collection5/501.txt     \n","  inflating: Collection5/502.ann     \n","  inflating: Collection5/502.txt     \n","  inflating: Collection5/503.ann     \n","  inflating: Collection5/503.txt     \n","  inflating: Collection5/504.ann     \n","  inflating: Collection5/504.txt     \n","  inflating: Collection5/505.ann     \n","  inflating: Collection5/505.txt     \n","  inflating: Collection5/506.ann     \n","  inflating: Collection5/506.txt     \n","  inflating: Collection5/507.ann     \n","  inflating: Collection5/507.txt     \n","  inflating: Collection5/508.ann     \n","  inflating: Collection5/508.txt     \n","  inflating: Collection5/509.ann     \n","  inflating: Collection5/509.txt     \n","  inflating: Collection5/510.ann     \n","  inflating: Collection5/510.txt     \n","  inflating: Collection5/511.ann     \n","  inflating: Collection5/511.txt     \n","  inflating: Collection5/512.ann     \n","  inflating: Collection5/512.txt     \n","  inflating: Collection5/513.ann     \n","  inflating: Collection5/513.txt     \n","  inflating: Collection5/514.ann     \n","  inflating: Collection5/514.txt     \n","  inflating: Collection5/515.ann     \n","  inflating: Collection5/515.txt     \n","  inflating: Collection5/516.ann     \n","  inflating: Collection5/516.txt     \n","  inflating: Collection5/517.ann     \n","  inflating: Collection5/517.txt     \n","  inflating: Collection5/518.ann     \n","  inflating: Collection5/518.txt     \n","  inflating: Collection5/519.ann     \n","  inflating: Collection5/519.txt     \n","  inflating: Collection5/520.ann     \n","  inflating: Collection5/520.txt     \n","  inflating: Collection5/521.ann     \n","  inflating: Collection5/521.txt     \n","  inflating: Collection5/522.ann     \n","  inflating: Collection5/522.txt     \n","  inflating: Collection5/523.ann     \n","  inflating: Collection5/523.txt     \n","  inflating: Collection5/524.ann     \n","  inflating: Collection5/524.txt     \n","  inflating: Collection5/525.ann     \n","  inflating: Collection5/525.txt     \n","  inflating: Collection5/526.ann     \n","  inflating: Collection5/526.txt     \n","  inflating: Collection5/527.ann     \n","  inflating: Collection5/527.txt     \n","  inflating: Collection5/528.ann     \n","  inflating: Collection5/528.txt     \n","  inflating: Collection5/529.ann     \n","  inflating: Collection5/529.txt     \n","  inflating: Collection5/530.ann     \n","  inflating: Collection5/530.txt     \n","  inflating: Collection5/531.ann     \n","  inflating: Collection5/531.txt     \n","  inflating: Collection5/532.ann     \n","  inflating: Collection5/532.txt     \n","  inflating: Collection5/533 (!).ann  \n","  inflating: Collection5/533 (!).txt  \n","  inflating: Collection5/534.ann     \n","  inflating: Collection5/534.txt     \n","  inflating: Collection5/535.ann     \n","  inflating: Collection5/535.txt     \n","  inflating: Collection5/536.ann     \n","  inflating: Collection5/536.txt     \n","  inflating: Collection5/537.ann     \n","  inflating: Collection5/537.txt     \n","  inflating: Collection5/538.ann     \n","  inflating: Collection5/538.txt     \n","  inflating: Collection5/539.ann     \n","  inflating: Collection5/539.txt     \n","  inflating: Collection5/540.ann     \n","  inflating: Collection5/540.txt     \n","  inflating: Collection5/541.ann     \n","  inflating: Collection5/541.txt     \n","  inflating: Collection5/542.ann     \n","  inflating: Collection5/542.txt     \n","  inflating: Collection5/543.ann     \n","  inflating: Collection5/543.txt     \n","  inflating: Collection5/544.ann     \n","  inflating: Collection5/544.txt     \n","  inflating: Collection5/545.ann     \n","  inflating: Collection5/545.txt     \n","  inflating: Collection5/546.ann     \n","  inflating: Collection5/546.txt     \n","  inflating: Collection5/547.ann     \n","  inflating: Collection5/547.txt     \n","  inflating: Collection5/548.ann     \n","  inflating: Collection5/548.txt     \n","  inflating: Collection5/549.ann     \n","  inflating: Collection5/549.txt     \n","  inflating: Collection5/550.ann     \n","  inflating: Collection5/550.txt     \n","  inflating: Collection5/551.ann     \n","  inflating: Collection5/551.txt     \n","  inflating: Collection5/552.ann     \n","  inflating: Collection5/552.txt     \n","  inflating: Collection5/553.ann     \n","  inflating: Collection5/553.txt     \n","  inflating: Collection5/554.ann     \n","  inflating: Collection5/554.txt     \n","  inflating: Collection5/555 (!).ann  \n","  inflating: Collection5/555 (!).txt  \n","  inflating: Collection5/556.ann     \n","  inflating: Collection5/556.txt     \n","  inflating: Collection5/557.ann     \n","  inflating: Collection5/557.txt     \n","  inflating: Collection5/558.ann     \n","  inflating: Collection5/558.txt     \n","  inflating: Collection5/559.ann     \n","  inflating: Collection5/559.txt     \n","  inflating: Collection5/560.ann     \n","  inflating: Collection5/560.txt     \n","  inflating: Collection5/561.ann     \n","  inflating: Collection5/561.txt     \n","  inflating: Collection5/562.ann     \n","  inflating: Collection5/562.txt     \n","  inflating: Collection5/563.ann     \n","  inflating: Collection5/563.txt     \n","  inflating: Collection5/564.ann     \n","  inflating: Collection5/564.txt     \n","  inflating: Collection5/565.ann     \n","  inflating: Collection5/565.txt     \n","  inflating: Collection5/567.ann     \n","  inflating: Collection5/567.txt     \n","  inflating: Collection5/568.ann     \n","  inflating: Collection5/568.txt     \n","  inflating: Collection5/569.ann     \n","  inflating: Collection5/569.txt     \n","  inflating: Collection5/570.ann     \n","  inflating: Collection5/570.txt     \n","  inflating: Collection5/571.ann     \n","  inflating: Collection5/571.txt     \n","  inflating: Collection5/572.ann     \n","  inflating: Collection5/572.txt     \n","  inflating: Collection5/574.ann     \n","  inflating: Collection5/574.txt     \n","  inflating: Collection5/575.ann     \n","  inflating: Collection5/575.txt     \n","  inflating: Collection5/576.ann     \n","  inflating: Collection5/576.txt     \n","  inflating: Collection5/577.ann     \n","  inflating: Collection5/577.txt     \n","  inflating: Collection5/578.ann     \n","  inflating: Collection5/578.txt     \n","  inflating: Collection5/579.ann     \n","  inflating: Collection5/579.txt     \n","  inflating: Collection5/581.ann     \n","  inflating: Collection5/581.txt     \n","  inflating: Collection5/582.ann     \n","  inflating: Collection5/582.txt     \n","  inflating: Collection5/583.ann     \n","  inflating: Collection5/583.txt     \n","  inflating: Collection5/584 (!).ann  \n","  inflating: Collection5/584 (!).txt  \n","  inflating: Collection5/585.ann     \n","  inflating: Collection5/585.txt     \n","  inflating: Collection5/586.ann     \n","  inflating: Collection5/586.txt     \n","  inflating: Collection5/587.ann     \n","  inflating: Collection5/587.txt     \n","  inflating: Collection5/588.ann     \n","  inflating: Collection5/588.txt     \n","  inflating: Collection5/589.ann     \n","  inflating: Collection5/589.txt     \n","  inflating: Collection5/590.ann     \n","  inflating: Collection5/590.txt     \n","  inflating: Collection5/591.ann     \n","  inflating: Collection5/591.txt     \n","  inflating: Collection5/592.ann     \n","  inflating: Collection5/592.txt     \n","  inflating: Collection5/593.ann     \n","  inflating: Collection5/593.txt     \n","  inflating: Collection5/594.ann     \n","  inflating: Collection5/594.txt     \n","  inflating: Collection5/595.ann     \n","  inflating: Collection5/595.txt     \n","  inflating: Collection5/596.ann     \n","  inflating: Collection5/596.txt     \n","  inflating: Collection5/597.ann     \n","  inflating: Collection5/597.txt     \n","  inflating: Collection5/598 (!).ann  \n","  inflating: Collection5/598 (!).txt  \n","  inflating: Collection5/599.ann     \n","  inflating: Collection5/599.txt     \n","  inflating: Collection5/600.ann     \n","  inflating: Collection5/600.txt     \n","  inflating: Collection5/601.ann     \n","  inflating: Collection5/601.txt     \n","  inflating: Collection5/602.ann     \n","  inflating: Collection5/602.txt     \n","  inflating: Collection5/610.ann     \n","  inflating: Collection5/610.txt     \n","  inflating: Collection5/611.ann     \n","  inflating: Collection5/611.txt     \n","  inflating: Collection5/612.ann     \n","  inflating: Collection5/612.txt     \n","  inflating: Collection5/613.ann     \n","  inflating: Collection5/613.txt     \n","  inflating: Collection5/614.ann     \n","  inflating: Collection5/614.txt     \n","  inflating: Collection5/615.ann     \n","  inflating: Collection5/615.txt     \n","  inflating: Collection5/616.ann     \n","  inflating: Collection5/616.txt     \n","  inflating: Collection5/617.ann     \n","  inflating: Collection5/617.txt     \n","  inflating: Collection5/618.ann     \n","  inflating: Collection5/618.txt     \n","  inflating: Collection5/619.ann     \n","  inflating: Collection5/619.txt     \n","  inflating: Collection5/620.ann     \n","  inflating: Collection5/620.txt     \n","  inflating: Collection5/621.ann     \n","  inflating: Collection5/621.txt     \n","  inflating: Collection5/622.ann     \n","  inflating: Collection5/622.txt     \n","  inflating: Collection5/623.ann     \n","  inflating: Collection5/623.txt     \n","  inflating: Collection5/624.ann     \n","  inflating: Collection5/624.txt     \n","  inflating: Collection5/625.ann     \n","  inflating: Collection5/625.txt     \n","  inflating: Collection5/626.ann     \n","  inflating: Collection5/626.txt     \n","  inflating: Collection5/627.ann     \n","  inflating: Collection5/627.txt     \n","  inflating: Collection5/628.ann     \n","  inflating: Collection5/628.txt     \n","  inflating: Collection5/629.ann     \n","  inflating: Collection5/629.txt     \n","  inflating: Collection5/630.ann     \n","  inflating: Collection5/630.txt     \n","  inflating: Collection5/631.ann     \n","  inflating: Collection5/631.txt     \n","  inflating: Collection5/632.ann     \n","  inflating: Collection5/632.txt     \n","  inflating: Collection5/633.ann     \n","  inflating: Collection5/633.txt     \n","  inflating: Collection5/abdulatipov.ann  \n","  inflating: Collection5/abdulatipov.txt  \n","  inflating: Collection5/artjakov.ann  \n","  inflating: Collection5/artjakov.txt  \n","  inflating: Collection5/Avtovaz.ann  \n","  inflating: Collection5/Avtovaz.txt  \n","  inflating: Collection5/blokhin.ann  \n","  inflating: Collection5/blokhin.txt  \n","  inflating: Collection5/chaves.ann  \n","  inflating: Collection5/chaves.txt  \n","  inflating: Collection5/chirkunov.ann  \n","  inflating: Collection5/chirkunov.txt  \n","  inflating: Collection5/kamchatka.ann  \n","  inflating: Collection5/kamchatka.txt  \n","  inflating: Collection5/klinton.ann  \n","  inflating: Collection5/klinton.txt  \n","  inflating: Collection5/kuleshov.ann  \n","  inflating: Collection5/kuleshov.txt  \n","  inflating: Collection5/last_01.ann  \n","  inflating: Collection5/last_01.txt  \n","  inflating: Collection5/last_02.ann  \n","  inflating: Collection5/last_02.txt  \n","  inflating: Collection5/last_03.ann  \n","  inflating: Collection5/last_03.txt  \n","  inflating: Collection5/last_04.ann  \n","  inflating: Collection5/last_04.txt  \n","  inflating: Collection5/last_05.ann  \n","  inflating: Collection5/last_05.txt  \n","  inflating: Collection5/last_06.ann  \n","  inflating: Collection5/last_06.txt  \n","  inflating: Collection5/last_07_new.ann  \n","  inflating: Collection5/last_07_new.txt  \n","  inflating: Collection5/last_08.ann  \n","  inflating: Collection5/last_08.txt  \n","  inflating: Collection5/last_09.ann  \n","  inflating: Collection5/last_09.txt  \n","  inflating: Collection5/last_10.ann  \n","  inflating: Collection5/last_10.txt  \n","  inflating: Collection5/last_11.ann  \n","  inflating: Collection5/last_11.txt  \n","  inflating: Collection5/last_12.ann  \n","  inflating: Collection5/last_12.txt  \n","  inflating: Collection5/last_13.ann  \n","  inflating: Collection5/last_13.txt  \n","  inflating: Collection5/last_14.ann  \n","  inflating: Collection5/last_14.txt  \n","  inflating: Collection5/last_15.ann  \n","  inflating: Collection5/last_15.txt  \n","  inflating: Collection5/last_16.ann  \n","  inflating: Collection5/last_16.txt  \n","  inflating: Collection5/last_17.ann  \n","  inflating: Collection5/last_17.txt  \n","  inflating: Collection5/last_18.ann  \n","  inflating: Collection5/last_18.txt  \n","  inflating: Collection5/last_19.ann  \n","  inflating: Collection5/last_19.txt  \n","  inflating: Collection5/last_20.ann  \n","  inflating: Collection5/last_20.txt  \n","  inflating: Collection5/last_21.ann  \n","  inflating: Collection5/last_21.txt  \n","  inflating: Collection5/last_22.ann  \n","  inflating: Collection5/last_22.txt  \n","  inflating: Collection5/last_23.ann  \n","  inflating: Collection5/last_23.txt  \n","  inflating: Collection5/last_24.ann  \n","  inflating: Collection5/last_24.txt  \n","  inflating: Collection5/last_25.ann  \n","  inflating: Collection5/last_25.txt  \n","  inflating: Collection5/last_26.ann  \n","  inflating: Collection5/last_26.txt  \n","  inflating: Collection5/last_27.ann  \n","  inflating: Collection5/last_27.txt  \n","  inflating: Collection5/last_28.ann  \n","  inflating: Collection5/last_28.txt  \n","  inflating: Collection5/last_29.ann  \n","  inflating: Collection5/last_29.txt  \n","  inflating: Collection5/last_30_new.ann  \n","  inflating: Collection5/last_30_new.txt  \n","  inflating: Collection5/last_31.ann  \n","  inflating: Collection5/last_31.txt  \n","  inflating: Collection5/last_32.ann  \n","  inflating: Collection5/last_32.txt  \n","  inflating: Collection5/last_33.ann  \n","  inflating: Collection5/last_33.txt  \n","  inflating: Collection5/last_34.ann  \n","  inflating: Collection5/last_34.txt  \n","  inflating: Collection5/last_35.ann  \n","  inflating: Collection5/last_35.txt  \n","  inflating: Collection5/last_36.ann  \n","  inflating: Collection5/last_36.txt  \n","  inflating: Collection5/last_37.ann  \n","  inflating: Collection5/last_37.txt  \n","  inflating: Collection5/last_38.ann  \n","  inflating: Collection5/last_38.txt  \n","  inflating: Collection5/last_39.ann  \n","  inflating: Collection5/last_39.txt  \n","  inflating: Collection5/last_40.ann  \n","  inflating: Collection5/last_40.txt  \n","  inflating: Collection5/last_41.ann  \n","  inflating: Collection5/last_41.txt  \n","  inflating: Collection5/last_42.ann  \n","  inflating: Collection5/last_42.txt  \n","  inflating: Collection5/last_43.ann  \n","  inflating: Collection5/last_43.txt  \n","  inflating: Collection5/last_44.ann  \n","  inflating: Collection5/last_44.txt  \n","  inflating: Collection5/last_45.ann  \n","  inflating: Collection5/last_45.txt  \n","  inflating: Collection5/last_46.ann  \n","  inflating: Collection5/last_46.txt  \n","  inflating: Collection5/last_47.ann  \n","  inflating: Collection5/last_47.txt  \n","  inflating: Collection5/last_48.ann  \n","  inflating: Collection5/last_48.txt  \n","  inflating: Collection5/last_49.ann  \n","  inflating: Collection5/last_49.txt  \n","  inflating: Collection5/last_50.ann  \n","  inflating: Collection5/last_50.txt  \n","  inflating: Collection5/last_51.ann  \n","  inflating: Collection5/last_51.txt  \n","  inflating: Collection5/last_52.ann  \n","  inflating: Collection5/last_52.txt  \n","  inflating: Collection5/last_53.ann  \n","  inflating: Collection5/last_53.txt  \n","  inflating: Collection5/last_54.ann  \n","  inflating: Collection5/last_54.txt  \n","  inflating: Collection5/last_55.ann  \n","  inflating: Collection5/last_55.txt  \n","  inflating: Collection5/last_56.ann  \n","  inflating: Collection5/last_56.txt  \n","  inflating: Collection5/last_57.ann  \n","  inflating: Collection5/last_57.txt  \n","  inflating: Collection5/last_58.ann  \n","  inflating: Collection5/last_58.txt  \n","  inflating: Collection5/last_59.ann  \n","  inflating: Collection5/last_59.txt  \n","  inflating: Collection5/last_60.ann  \n","  inflating: Collection5/last_60.txt  \n","  inflating: Collection5/last_61.ann  \n","  inflating: Collection5/last_61.txt  \n","  inflating: Collection5/last_62.ann  \n","  inflating: Collection5/last_62.txt  \n","  inflating: Collection5/last_63.ann  \n","  inflating: Collection5/last_63.txt  \n","  inflating: Collection5/last_64.ann  \n","  inflating: Collection5/last_64.txt  \n","  inflating: Collection5/last_65.ann  \n","  inflating: Collection5/last_65.txt  \n","  inflating: Collection5/last_66.ann  \n","  inflating: Collection5/last_66.txt  \n","  inflating: Collection5/last_67.ann  \n","  inflating: Collection5/last_67.txt  \n","  inflating: Collection5/last_68.ann  \n","  inflating: Collection5/last_68.txt  \n","  inflating: Collection5/last_69.ann  \n","  inflating: Collection5/last_69.txt  \n","  inflating: Collection5/last_70.ann  \n","  inflating: Collection5/last_70.txt  \n","  inflating: Collection5/last_71.ann  \n","  inflating: Collection5/last_71.txt  \n","  inflating: Collection5/last_72.ann  \n","  inflating: Collection5/last_72.txt  \n","  inflating: Collection5/last_73.ann  \n","  inflating: Collection5/last_73.txt  \n","  inflating: Collection5/last_74.ann  \n","  inflating: Collection5/last_74.txt  \n","  inflating: Collection5/last_75.ann  \n","  inflating: Collection5/last_75.txt  \n","  inflating: Collection5/lenoblast.ann  \n","  inflating: Collection5/lenoblast.txt  \n","  inflating: Collection5/maykl dzhekson.ann  \n","  inflating: Collection5/maykl dzhekson.txt  \n","  inflating: Collection5/mvd.ann     \n","  inflating: Collection5/mvd.txt     \n","  inflating: Collection5/mvd2.ann    \n","  inflating: Collection5/mvd2.txt    \n","  inflating: Collection5/rosobrnadzor.ann  \n","  inflating: Collection5/rosobrnadzor.txt  \n","  inflating: Collection5/ryadovoy chelah.ann  \n","  inflating: Collection5/ryadovoy chelah.txt  \n","  inflating: Collection5/semenenko.ann  \n","  inflating: Collection5/semenenko.txt  \n","  inflating: Collection5/shojgu1.ann  \n","  inflating: Collection5/shojgu1.txt  \n","  inflating: Collection5/shojgu3.ann  \n","  inflating: Collection5/shojgu3.txt  \n","  inflating: Collection5/shojgu4.ann  \n","  inflating: Collection5/shojgu4.txt  \n","  inflating: Collection5/shojgu6.ann  \n","  inflating: Collection5/shojgu6.txt  \n","  inflating: Collection5/si_tzjanpin.ann  \n","  inflating: Collection5/si_tzjanpin.txt  \n","  inflating: Collection5/sobjanin2.ann  \n","  inflating: Collection5/sobjanin2.txt  \n","  inflating: Collection5/turkmenija.ann  \n","  inflating: Collection5/turkmenija.txt  \n","  inflating: Collection5/uchitel.ann  \n","  inflating: Collection5/uchitel.txt  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JPxCa2LyH8gW","executionInfo":{"status":"ok","timestamp":1625686516360,"user_tz":-180,"elapsed":288,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["!rm collection5.zip"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7burz-bD3t4l","executionInfo":{"status":"ok","timestamp":1625686520045,"user_tz":-180,"elapsed":259,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"17090716-551b-4920-eabd-7062fd655802"},"source":["!ls"],"execution_count":39,"outputs":[{"output_type":"stream","text":["Collection5  datasets  sample_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UEdS2pAS3fod","executionInfo":{"status":"ok","timestamp":1625686524946,"user_tz":-180,"elapsed":269,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["from corus import load_ne5\n","\n","dir = 'Collection5/'\n","records = load_ne5(dir)\n","rec = next(records)\n"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TuzGqeSclcWw","executionInfo":{"status":"ok","timestamp":1625686529823,"user_tz":-180,"elapsed":264,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"9db2f857-6972-4894-9637-930a3a719318"},"source":["rec.spans"],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Ne5Span(\n","     index='T1',\n","     type='ORG',\n","     start=6,\n","     stop=8,\n","     text='СК'\n"," ), Ne5Span(\n","     index='T2',\n","     type='ORG',\n","     start=40,\n","     stop=56,\n","     text='Балтийском флоте'\n"," ), Ne5Span(\n","     index='T3',\n","     type='ORG',\n","     start=60,\n","     stop=80,\n","     text='Следственный комитет'\n"," ), Ne5Span(\n","     index='T4',\n","     type='ORG',\n","     start=163,\n","     stop=206,\n","     text='ОАО «Управление торговли Балтийского флота»'\n"," ), Ne5Span(\n","     index='T5',\n","     type='PER',\n","     start=207,\n","     stop=227,\n","     text='Максима Малаховского'\n"," ), Ne5Span(\n","     index='T6',\n","     type='PER',\n","     start=362,\n","     stop=375,\n","     text='М.Малаховский'\n"," ), Ne5Span(\n","     index='T7',\n","     type='ORG',\n","     start=505,\n","     stop=549,\n","     text='ООО «Калининградский межотраслевой комбинат»'\n"," ), Ne5Span(\n","     index='T8',\n","     type='ORG',\n","     start=551,\n","     stop=590,\n","     text='ООО «Балтийский межотраслевой комбинат»'\n"," ), Ne5Span(\n","     index='T9',\n","     type='ORG',\n","     start=593,\n","     stop=633,\n","     text='ООО «Гвардейский межотраслевой комбинат»'\n"," ), Ne5Span(\n","     index='T10',\n","     type='PER',\n","     start=650,\n","     stop=663,\n","     text='М.Малаховский'\n"," ), Ne5Span(\n","     index='T11',\n","     type='ORG',\n","     start=759,\n","     stop=773,\n","     text='ОАО «Военторг»'\n"," ), Ne5Span(\n","     index='T12',\n","     type='ORG',\n","     start=794,\n","     stop=812,\n","     text='ОАО «Оборонсервис»'\n"," ), Ne5Span(\n","     index='T13',\n","     type='ORG',\n","     start=904,\n","     stop=947,\n","     text='ОАО «Управление торговли Балтийского флота»'\n"," ), Ne5Span(\n","     index='T14',\n","     type='PER',\n","     start=1242,\n","     stop=1256,\n","     text='М.Малаховского'\n"," ), Ne5Span(\n","     index='T15',\n","     type='MEDIA',\n","     start=1298,\n","     stop=1310,\n","     text='Новой газете'\n"," ), Ne5Span(\n","     index='T16',\n","     type='PER',\n","     start=1333,\n","     stop=1346,\n","     text='М.Малаховский'\n"," ), Ne5Span(\n","     index='T17',\n","     type='GEOPOLIT',\n","     start=1421,\n","     stop=1428,\n","     text='Москвой'\n"," ), Ne5Span(\n","     index='T18',\n","     type='ORG',\n","     start=1473,\n","     stop=1488,\n","     text='Арбитражный суд'\n"," ), Ne5Span(\n","     index='T19',\n","     type='LOC',\n","     start=1489,\n","     stop=1495,\n","     text='Москвы'\n"," ), Ne5Span(\n","     index='T20',\n","     type='ORG',\n","     start=1574,\n","     stop=1583,\n","     text='Военторга'\n"," ), Ne5Span(\n","     index='T21',\n","     type='PER',\n","     start=1620,\n","     stop=1633,\n","     text='М.Малаховский'\n"," ), Ne5Span(\n","     index='T22',\n","     type='ORG',\n","     start=1646,\n","     stop=1681,\n","     text='Военного Краснознаменного института'\n"," ), Ne5Span(\n","     index='T23',\n","     type='ORG',\n","     start=1704,\n","     stop=1741,\n","     text='Управление торговли Балтийского флота'\n"," ), Ne5Span(\n","     index='T24',\n","     type='ORG',\n","     start=1759,\n","     stop=1769,\n","     text='Минобороны'\n"," ), Ne5Span(\n","     index='T25',\n","     type='ORG',\n","     start=1791,\n","     stop=1800,\n","     text='Военторга'\n"," )]"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q9c84CRFlf7s","executionInfo":{"status":"ok","timestamp":1625686538039,"user_tz":-180,"elapsed":4228,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"46dcbe94-e7e8-42e8-ae77-78cf944a2b91"},"source":["!pip install razdel"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Collecting razdel\n","  Downloading https://files.pythonhosted.org/packages/15/2c/664223a3924aa6e70479f7d37220b3a658765b9cfe760b4af7ffdc50d38f/razdel-0.5.0-py3-none-any.whl\n","Installing collected packages: razdel\n","Successfully installed razdel-0.5.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3g9PoTmJllsI","executionInfo":{"status":"ok","timestamp":1625686540484,"user_tz":-180,"elapsed":245,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["from razdel import tokenize"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"7snD9_1Qll2T","executionInfo":{"status":"ok","timestamp":1625686547411,"user_tz":-180,"elapsed":4773,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["words_docs = []\n","for ix, rec in enumerate(records):\n","    words = []\n","    for token in tokenize(rec.text):\n","        is_person = False\n","        for person in rec.spans:\n","            if (token.start >= person.start) and (token.stop <= person.stop):\n","                is_person = True\n","                break\n","        words.append([token.text, 'PERSON' if is_person else 'NO_PERSON'])\n","    words_docs.extend(words)"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"id":"P5wgdUiOll9w","executionInfo":{"status":"ok","timestamp":1625686550882,"user_tz":-180,"elapsed":257,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["import pandas as pd"],"execution_count":45,"outputs":[]},{"cell_type":"code","metadata":{"id":"UJenxhewlmA-","executionInfo":{"status":"ok","timestamp":1625686552583,"user_tz":-180,"elapsed":251,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["df_words = pd.DataFrame(words_docs, columns=['word', 'tag'])"],"execution_count":46,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yvUqbhDMl3ZZ","executionInfo":{"status":"ok","timestamp":1625686554159,"user_tz":-180,"elapsed":402,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"db509b41-270b-4bbd-96e8-aa8c5b765bbe"},"source":["df_words['tag'].value_counts()"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NO_PERSON    218995\n","PERSON        46179\n","Name: tag, dtype: int64"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":670},"id":"SkFaghV9l3i0","executionInfo":{"status":"ok","timestamp":1625686556888,"user_tz":-180,"elapsed":261,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"508c9c19-d35a-4349-a920-2f5df5a1445f"},"source":["df_words.head(20)"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>word</th>\n","      <th>tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Шанцев</td>\n","      <td>PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>скорректировал</td>\n","      <td>NO_PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>структуру</td>\n","      <td>NO_PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>нижегородского</td>\n","      <td>NO_PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>правительства</td>\n","      <td>NO_PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>и</td>\n","      <td>NO_PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>назначил</td>\n","      <td>NO_PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>себе</td>\n","      <td>NO_PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>новых</td>\n","      <td>NO_PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>заместителей</td>\n","      <td>NO_PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Губернатор</td>\n","      <td>NO_PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>Валерий</td>\n","      <td>PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>Шанцев</td>\n","      <td>PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>внес</td>\n","      <td>NO_PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>кадровые</td>\n","      <td>NO_PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>изменения</td>\n","      <td>NO_PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>в</td>\n","      <td>NO_PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>состав</td>\n","      <td>NO_PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>правительства</td>\n","      <td>NO_PERSON</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>Нижегородской</td>\n","      <td>PERSON</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["              word        tag\n","0           Шанцев     PERSON\n","1   скорректировал  NO_PERSON\n","2        структуру  NO_PERSON\n","3   нижегородского  NO_PERSON\n","4    правительства  NO_PERSON\n","5                и  NO_PERSON\n","6         назначил  NO_PERSON\n","7             себе  NO_PERSON\n","8            новых  NO_PERSON\n","9     заместителей  NO_PERSON\n","10      Губернатор  NO_PERSON\n","11         Валерий     PERSON\n","12          Шанцев     PERSON\n","13            внес  NO_PERSON\n","14        кадровые  NO_PERSON\n","15       изменения  NO_PERSON\n","16               в  NO_PERSON\n","17          состав  NO_PERSON\n","18   правительства  NO_PERSON\n","19   Нижегородской     PERSON"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"markdown","metadata":{"id":"EW9bHconknfx"},"source":["#### 1.взять нер из nltk"]},{"cell_type":"code","metadata":{"id":"uRuODJpkIqlv","executionInfo":{"status":"ok","timestamp":1625686565303,"user_tz":-180,"elapsed":250,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["import nltk\n","from nltk import word_tokenize, pos_tag, ne_chunk"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L4Thrc-imlMK","executionInfo":{"status":"ok","timestamp":1625686574668,"user_tz":-180,"elapsed":6622,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"f913aa8e-9b4b-49a5-c880-e9b213afc6d3"},"source":["nltk.download('maxent_ne_chunker')\n","nltk.download('punkt')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('words')"],"execution_count":50,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package maxent_ne_chunker to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package words to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/words.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WPQewgTPrgCC","executionInfo":{"status":"ok","timestamp":1625686577058,"user_tz":-180,"elapsed":414,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"ab7c812e-7d2d-45d3-c51d-d0595ad5a6d1"},"source":["nltk.pos_tag(nltk.word_tokenize(rec.text))"],"execution_count":51,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Вице-мэром', 'JJ'),\n"," ('Новосибирска', 'NNP'),\n"," ('по', 'NNP'),\n"," ('социальным', 'NNP'),\n"," ('вопросам', 'NNP'),\n"," ('стал', 'NNP'),\n"," ('учитель', 'VBD'),\n"," ('10:14', 'CD'),\n"," ('31.01.2013', 'CD'),\n"," ('Мэр', 'NN'),\n"," ('Новосибирска', 'NNP'),\n"," ('Владимир', 'NNP'),\n"," ('Городецкий', 'NNP'),\n"," ('назначил', 'NNP'),\n"," ('своим', 'NNP'),\n"," ('заместителем', 'NNP'),\n"," ('по', 'NNP'),\n"," ('социальным', 'NNP'),\n"," ('вопросам', 'NNP'),\n"," ('бывшего', 'NNP'),\n"," ('замначальника', 'NNP'),\n"," ('городского', 'NNP'),\n"," ('управления', 'NNP'),\n"," ('образования', 'NNP'),\n"," ('Сергея', 'NNP'),\n"," ('Нелюбова', 'NNP'),\n"," (';', ':'),\n"," ('главным', 'NNP'),\n"," ('финансистом', 'NNP'),\n"," ('города', 'NNP'),\n"," ('стал', 'NNP'),\n"," ('бывший', 'NNP'),\n"," ('первый', 'NNP'),\n"," ('замглавы', 'NNP'),\n"," ('Бердска', 'NNP'),\n"," ('Владимир', 'NNP'),\n"," ('Штоп', 'NNP'),\n"," ('.', '.')]"]},"metadata":{"tags":[]},"execution_count":51}]},{"cell_type":"code","metadata":{"id":"skYaNCiC5xM4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625686595567,"user_tz":-180,"elapsed":268,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"f3493874-09e5-4ddb-e813-dfd6a97086a5"},"source":["{(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(rec.text))) if hasattr(chunk, 'label') }"],"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{('Бердска Владимир Штоп', 'PERSON'),\n"," ('Новосибирска Владимир Городецкий', 'PERSON'),\n"," ('Сергея Нелюбова', 'PERSON')}"]},"metadata":{"tags":[]},"execution_count":52}]},{"cell_type":"markdown","metadata":{"id":"64rHv9lcnLd4"},"source":["#### 2.проверить deeppavlov"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"2kd-emBao1u-","executionInfo":{"status":"ok","timestamp":1625686709965,"user_tz":-180,"elapsed":107688,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"29716781-3f1c-4e12-cf99-c89ea12077a4"},"source":["# установка deeppavlov\n","\n","!pip uninstall -y tensorflow tensorflow-gpu\n","!pip install numpy scipy librosa unidecode inflect librosa transformers\n","!pip install deeppavlov"],"execution_count":53,"outputs":[{"output_type":"stream","text":["Uninstalling tensorflow-2.5.0:\n","  Successfully uninstalled tensorflow-2.5.0\n","\u001b[33mWARNING: Skipping tensorflow-gpu as it is not installed.\u001b[0m\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.7/dist-packages (0.8.1)\n","Collecting unidecode\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n","\u001b[K     |████████████████████████████████| 245kB 5.1MB/s \n","\u001b[?25hRequirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (2.1.0)\n","Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/1a/41c644c963249fd7f3836d926afa1e3f1cc234a1c40d80c5f03ad8f6f1b2/transformers-4.8.2-py3-none-any.whl (2.5MB)\n","\u001b[K     |████████████████████████████████| 2.5MB 19.8MB/s \n","\u001b[?25hRequirement already satisfied: soundfile>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.10.3.post1)\n","Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.4.0)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.7/dist-packages (from librosa) (1.0.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (20.9)\n","Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.2.2)\n","Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.22.2.post1)\n","Requirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (0.51.2)\n","Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from librosa) (2.1.9)\n","Collecting huggingface-hub==0.0.12\n","  Downloading https://files.pythonhosted.org/packages/2f/ee/97e253668fda9b17e968b3f97b2f8e53aa0127e8807d24a547687423fe0b/huggingface_hub-0.0.12-py3-none-any.whl\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 32.8MB/s \n","\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 36.8MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.7/dist-packages (from soundfile>=0.10.2->librosa) (1.14.5)\n","Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from pooch>=1.0->librosa) (1.4.4)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->librosa) (2.4.7)\n","Requirement already satisfied: six>=1.3 in /usr/local/lib/python3.7/dist-packages (from resampy>=0.2.2->librosa) (1.15.0)\n","Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (0.34.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.43.0->librosa) (57.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.0->soundfile>=0.10.2->librosa) (2.20)\n","Installing collected packages: unidecode, huggingface-hub, sacremoses, tokenizers, transformers\n","Successfully installed huggingface-hub-0.0.12 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.8.2 unidecode-1.2.0\n","Collecting deeppavlov\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/22/87/e77ccc7de09f8c5c4a3d981ff6b1d3811d9978976a30bec9bdf50d667ebb/deeppavlov-0.15.0-py3-none-any.whl (907kB)\n","\u001b[K     |████████████████████████████████| 911kB 5.2MB/s \n","\u001b[?25hCollecting requests==2.22.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n","\u001b[K     |████████████████████████████████| 61kB 6.7MB/s \n","\u001b[?25hCollecting pydantic==1.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/56/1f652c3f658d2a9fd495d2e988a2da57eabdb6c4b8f4563c2ccbe6a2a8c5/pydantic-1.3-cp37-cp37m-manylinux2010_x86_64.whl (7.3MB)\n","\u001b[K     |████████████████████████████████| 7.3MB 15.8MB/s \n","\u001b[?25hCollecting uvloop==0.14.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/7a/54a80c03b555af21680a2f3692947b43a0d576d90c4c18cace0fee1ccc0e/uvloop-0.14.0-cp37-cp37m-manylinux2010_x86_64.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 36.6MB/s \n","\u001b[?25hCollecting overrides==2.7.0\n","  Downloading https://files.pythonhosted.org/packages/ac/98/2430afd204c48ac0a529d439d7e22df8fa603c668d03456b5947cb59ec36/overrides-2.7.0.tar.gz\n","Collecting pytz==2019.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n","\u001b[K     |████████████████████████████████| 512kB 31.3MB/s \n","\u001b[?25hCollecting sacremoses==0.0.35\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n","\u001b[K     |████████████████████████████████| 860kB 19.0MB/s \n","\u001b[?25hCollecting h5py==2.10.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 31.1MB/s \n","\u001b[?25hRequirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (7.1.2)\n","Collecting nltk==3.4.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 29.3MB/s \n","\u001b[?25hCollecting aio-pika==6.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/07/196a4115cbef31fa0c3dabdea146f02dffe5e49998341d20dbe2278953bc/aio_pika-6.4.1-py3-none-any.whl (40kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.3MB/s \n","\u001b[?25hCollecting numpy==1.18.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/53/127cb49435bcf5d841baf8eafa030931c62a9eac577a641f8c2293d23371/numpy-1.18.0-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n","\u001b[K     |████████████████████████████████| 20.1MB 1.4MB/s \n","\u001b[?25hRequirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.0.12)\n","Collecting pymorphy2==0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n","\u001b[K     |████████████████████████████████| 51kB 4.7MB/s \n","\u001b[?25hCollecting pymorphy2-dicts-ru\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n","\u001b[K     |████████████████████████████████| 8.2MB 16.7MB/s \n","\u001b[?25hCollecting rusenttokenize==0.0.5\n","  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n","Collecting pytelegrambotapi==3.6.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/99c606f69fcda57e35788b913dd34c9d9acb48dd26349141b3855dcf6351/pyTelegramBotAPI-3.6.7.tar.gz (65kB)\n","\u001b[K     |████████████████████████████████| 71kB 8.3MB/s \n","\u001b[?25hCollecting scikit-learn==0.21.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/a4/a48bd4b0d15395362b561df7e7247de87291105eb736a3b2aaffebf437b9/scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7MB)\n","\u001b[K     |████████████████████████████████| 6.7MB 37.0MB/s \n","\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.4.1)\n","Collecting pyopenssl==19.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 5.9MB/s \n","\u001b[?25hCollecting ruamel.yaml==0.15.100\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/fc/12de89822adaa3a60b8cb0139bae75918278999d08e6dff158623abd7cba/ruamel.yaml-0.15.100-cp37-cp37m-manylinux1_x86_64.whl (654kB)\n","\u001b[K     |████████████████████████████████| 655kB 30.1MB/s \n","\u001b[?25hCollecting prometheus-client==0.7.1\n","  Downloading https://files.pythonhosted.org/packages/b3/23/41a5a24b502d35a4ad50a5bb7202a5e1d9a0364d0c12f56db3dbf7aca76d/prometheus_client-0.7.1.tar.gz\n","Collecting uvicorn==0.11.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/5f/2bc87272f189662e129ddcd4807ad3ef83128b4df3a3482335f5f9790f24/uvicorn-0.11.7-py3-none-any.whl (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.3MB/s \n","\u001b[?25hCollecting Cython==0.29.14\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/58/2deb24de3c10cc4c0f09639b46f4f4b50059f0fdc785128a57dd9fdce026/Cython-0.29.14-cp37-cp37m-manylinux1_x86_64.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 28.3MB/s \n","\u001b[?25hRequirement already satisfied: tqdm==4.41.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (4.41.1)\n","Collecting fastapi==0.47.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/a7/4804d7abf8a1544d079d50650af872387154ebdac5bd07d54b2e60e2b334/fastapi-0.47.1-py3-none-any.whl (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n","\u001b[?25hCollecting pandas==0.25.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/e0/a1b39cdcb2c391f087a1538bc8a6d62a82d0439693192aef541d7b123769/pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4MB)\n","\u001b[K     |████████████████████████████████| 10.4MB 28.1MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n","Collecting idna<2.9,>=2.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n","\u001b[K     |████████████████████████████████| 61kB 6.6MB/s \n","\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->deeppavlov) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses==0.0.35->deeppavlov) (1.0.1)\n","Collecting aiormq<4,>=3.2.0\n","  Downloading https://files.pythonhosted.org/packages/0b/c4/dc5b9d50c15af2ee187974a5a0c3f20c06cce6559eea4c065d372e846b6a/aiormq-3.3.1-py3-none-any.whl\n","Collecting yarl\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n","\u001b[K     |████████████████████████████████| 296kB 34.8MB/s \n","\u001b[?25hCollecting dawg-python>=0.7\n","  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n","Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n","Collecting pymorphy2-dicts<3.0,>=2.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n","\u001b[K     |████████████████████████████████| 7.1MB 35.4MB/s \n","\u001b[?25hCollecting cryptography>=2.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 30.3MB/s \n","\u001b[?25hCollecting httptools==0.1.*; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"PyPy\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/2e/485131e3aa113929b425f83854fafc190aa7df716cbeb258c875752f0c6e/httptools-0.1.2-cp37-cp37m-manylinux1_x86_64.whl (219kB)\n","\u001b[K     |████████████████████████████████| 225kB 43.1MB/s \n","\u001b[?25hCollecting websockets==8.*\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/0b/3ebc752392a368af14dd24ee041683416ac6d2463eead94b311b11e41c82/websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79kB)\n","\u001b[K     |████████████████████████████████| 81kB 8.6MB/s \n","\u001b[?25hCollecting h11<0.10,>=0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 6.9MB/s \n","\u001b[?25hCollecting starlette<=0.12.9,>=0.12.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/95/2220fe5bf287e693a6430d8ee36c681b0157035b7249ec08f8fb36319d16/starlette-0.12.9.tar.gz (46kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.1)\n","Collecting pamqp==2.3.0\n","  Downloading https://files.pythonhosted.org/packages/eb/56/afa06143361e640c9159d828dadc95fc9195c52c95b4a97d136617b0166d/pamqp-2.3.0-py2.py3-none-any.whl\n","Collecting multidict>=4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n","\u001b[K     |████████████████████████████████| 143kB 40.8MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (3.7.4.3)\n","Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (1.14.5)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (2.20)\n","Building wheels for collected packages: overrides, sacremoses, nltk, pytelegrambotapi, prometheus-client, starlette\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-2.7.0-cp37-none-any.whl size=5606 sha256=b7790f5c32f5b2880637f34c0755d5047ce54e10d18b81aca76f690e7c0018a9\n","  Stored in directory: /root/.cache/pip/wheels/8c/7c/ef/80508418b67d87371c5b3de49e03eb22ee7c1d19affb5099f8\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp37-none-any.whl size=883990 sha256=d0327654237592e7d1dbe432742228e004bf8f30408a9166c2d1f9c653cfd721\n","  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.4.5-cp37-none-any.whl size=1449923 sha256=78e79060bbf282816a19dfb39808471cd521fd50f165c6087e2d376cc53da96c\n","  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n","  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-cp37-none-any.whl size=47177 sha256=fa4dd1895f198c889dda01b773c1bc878b7f95e57db19d4870a4e3a6bfd4ee2d\n","  Stored in directory: /root/.cache/pip/wheels/23/40/18/8a34153f95ef0dc19e3954898e5a5079244b76a8afdd7d0ec5\n","  Building wheel for prometheus-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-cp37-none-any.whl size=41404 sha256=c7e87cd7c82d8fef745ec73e5f6d215b324c91c4fd6b28b8f4e5a05188bbe681\n","  Stored in directory: /root/.cache/pip/wheels/1c/54/34/fd47cd9b308826cc4292b54449c1899a30251ef3b506bc91ea\n","  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for starlette: filename=starlette-0.12.9-cp37-none-any.whl size=57254 sha256=0b4b5e5abef8a6da1960be4421c0fe245ee256ec1331097b21015f2de36a0b58\n","  Stored in directory: /root/.cache/pip/wheels/1c/51/5b/3828d52e185cafad941c4291b6f70894d0794be28c70addae5\n","Successfully built overrides sacremoses nltk pytelegrambotapi prometheus-client starlette\n","\u001b[31mERROR: kapre 0.3.5 requires tensorflow>=2.0.0, which is not installed.\u001b[0m\n","\u001b[31mERROR: xarray 0.18.2 has requirement pandas>=1.0, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: kapre 0.3.5 has requirement numpy>=1.18.5, but you'll have numpy 1.18.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: idna, requests, pydantic, uvloop, overrides, pytz, sacremoses, numpy, h5py, nltk, multidict, yarl, pamqp, aiormq, aio-pika, dawg-python, pymorphy2-dicts, pymorphy2, pymorphy2-dicts-ru, rusenttokenize, pytelegrambotapi, scikit-learn, cryptography, pyopenssl, ruamel.yaml, prometheus-client, httptools, websockets, h11, uvicorn, Cython, starlette, fastapi, pandas, deeppavlov\n","  Found existing installation: idna 2.10\n","    Uninstalling idna-2.10:\n","      Successfully uninstalled idna-2.10\n","  Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Found existing installation: pytz 2018.9\n","    Uninstalling pytz-2018.9:\n","      Successfully uninstalled pytz-2018.9\n","  Found existing installation: sacremoses 0.0.45\n","    Uninstalling sacremoses-0.0.45:\n","      Successfully uninstalled sacremoses-0.0.45\n","  Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Found existing installation: h5py 3.1.0\n","    Uninstalling h5py-3.1.0:\n","      Successfully uninstalled h5py-3.1.0\n","  Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","  Found existing installation: prometheus-client 0.11.0\n","    Uninstalling prometheus-client-0.11.0:\n","      Successfully uninstalled prometheus-client-0.11.0\n","  Found existing installation: Cython 0.29.23\n","    Uninstalling Cython-0.29.23:\n","      Successfully uninstalled Cython-0.29.23\n","  Found existing installation: pandas 1.1.5\n","    Uninstalling pandas-1.1.5:\n","      Successfully uninstalled pandas-1.1.5\n","Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.3.1 cryptography-3.4.7 dawg-python-0.7.2 deeppavlov-0.15.0 fastapi-0.47.1 h11-0.9.0 h5py-2.10.0 httptools-0.1.2 idna-2.8 multidict-5.1.0 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 prometheus-client-0.7.1 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.417127.4579844 pyopenssl-19.1.0 pytelegrambotapi-3.6.7 pytz-2019.1 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 sacremoses-0.0.35 scikit-learn-0.21.2 starlette-0.12.9 uvicorn-0.11.7 uvloop-0.14.0 websockets-8.1 yarl-1.6.3\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["idna","nltk","numpy","pandas","pytz","requests","sklearn"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"KY96lqBzsZJ_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625686769881,"user_tz":-180,"elapsed":50266,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"f9bbdc01-7c2d-4ede-e265-e5b05c0c497b"},"source":["!python -m deeppavlov install squad_bert\n","!python -m deeppavlov install ner_ontonotes"],"execution_count":54,"outputs":[{"output_type":"stream","text":["2021-07-07 19:38:41.602 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'squad_bert' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/squad/squad_bert.json'\n","Collecting tensorflow==1.15.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/81/84fb7a323f9723f81edfc796d89e89aa95a9446ed7353c144195b3a3a3ba/tensorflow-1.15.2-cp37-cp37m-manylinux2010_x86_64.whl (110.5MB)\n","\u001b[K     |████████████████████████████████| 110.5MB 79kB/s \n","\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n","Collecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.12.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.3.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.12.4)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.0)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 25.7MB/s \n","\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.36.2)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.12.0)\n","Collecting keras-applications>=1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n","\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.34.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.8.1)\n","Collecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 31.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.18.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.2) (57.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (4.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.4.1)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7557 sha256=caafe5197ae37240814c1476dec84fe72c1252374fc919cf819c68753c34bc8a\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: kapre 0.3.5 has requirement numpy>=1.18.5, but you'll have numpy 1.18.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: kapre 0.3.5 has requirement tensorflow>=2.0.0, but you'll have tensorflow 1.15.2 which is incompatible.\u001b[0m\n","Installing collected packages: gast, tensorboard, keras-applications, tensorflow-estimator, tensorflow\n","  Found existing installation: gast 0.4.0\n","    Uninstalling gast-0.4.0:\n","      Successfully uninstalled gast-0.4.0\n","  Found existing installation: tensorboard 2.5.0\n","    Uninstalling tensorboard-2.5.0:\n","      Successfully uninstalled tensorboard-2.5.0\n","  Found existing installation: tensorflow-estimator 2.5.0\n","    Uninstalling tensorflow-estimator-2.5.0:\n","      Successfully uninstalled tensorflow-estimator-2.5.0\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.2 tensorflow-estimator-1.15.1\n","Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n","  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-xzou98vd\n","  Running command git clone -q https://github.com/deepmipt/bert.git /tmp/pip-req-build-xzou98vd\n","Building wheels for collected packages: bert-dp\n","  Building wheel for bert-dp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bert-dp: filename=bert_dp-1.0-cp37-none-any.whl size=23593 sha256=81d0aa11cad4812b1dd7ea12c920e383f966c763023ba8614ceb3335afab4fdc\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-j4zz9jr8/wheels/1e/41/94/886107eaf932532594886fd8bfc9cb9d4db632e94add49d326\n","Successfully built bert-dp\n","Installing collected packages: bert-dp\n","Successfully installed bert-dp-1.0\n","2021-07-07 19:39:16.940 INFO in 'deeppavlov.core.common.file'['file'] at line 32: Interpreting 'ner_ontonotes' as '/usr/local/lib/python3.7/dist-packages/deeppavlov/configs/ner/ner_ontonotes.json'\n","Collecting gensim==3.8.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/93/c6011037f24e3106d13f3be55297bf84ece2bf15b278cc4776339dc52db5/gensim-3.8.1-cp37-cp37m-manylinux1_x86_64.whl (24.2MB)\n","\u001b[K     |████████████████████████████████| 24.2MB 113kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.18.0)\n","Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.15.0)\n","Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (5.1.0)\n","Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.1) (1.4.1)\n","Installing collected packages: gensim\n","  Found existing installation: gensim 3.6.0\n","    Uninstalling gensim-3.6.0:\n","      Successfully uninstalled gensim-3.6.0\n","Successfully installed gensim-3.8.1\n","Requirement already satisfied: tensorflow==1.15.2 in /usr/local/lib/python3.7/dist-packages (1.15.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.12.4)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.2)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.1)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.18.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.1.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.2.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.12.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.34.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.12.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.8.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (0.36.2)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.15.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (1.0.8)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15.2) (3.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.2) (57.0.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.3.4)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (4.5.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.7.4.3)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6KE7tpVWs1b7","executionInfo":{"status":"ok","timestamp":1625686776376,"user_tz":-180,"elapsed":253,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["import deeppavlov\n","from deeppavlov import configs, build_model"],"execution_count":55,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wsegbgCbrzy_","executionInfo":{"status":"ok","timestamp":1625687113518,"user_tz":-180,"elapsed":334972,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"b138b993-925b-4c27-f463-e52b0077c6ec"},"source":["deeppavlov_ner = build_model(configs.ner.ner_bert_ent_and_type_rus, download=True)\n","rus_document = \"Нью-Йорк, США, 30 апреля 2020, 01:01 — REGNUM В администрации президента США Дональда Трампа планируют пройти все этапы создания вакцины от коронавируса в ускоренном темпе и выпустить 100 млн доз до конца 2020 года, передаёт агентство Bloomberg со ссылкой на осведомлённые источники\"\n","deeppavlov_ner([rus_document])"],"execution_count":56,"outputs":[{"output_type":"stream","text":["2021-07-07 19:39:39.621 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/kbqa/models/ner_cq_rus.tar.gz to /root/.deeppavlov/models/ner_cq_rus.tar.gz\n","100%|██████████| 1.32G/1.32G [02:33<00:00, 8.58MB/s]\n","2021-07-07 19:42:14.415 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/models/ner_cq_rus.tar.gz archive into /root/.deeppavlov/models/ner_ent_and_type_rus\n","2021-07-07 19:42:30.588 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12.zip to /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip\n","100%|██████████| 663M/663M [01:08<00:00, 9.62MB/s]\n","2021-07-07 19:43:40.526 INFO in 'deeppavlov.core.data.utils'['utils'] at line 272: Extracting /root/.deeppavlov/downloads/multi_cased_L-12_H-768_A-12.zip archive into /root/.deeppavlov/downloads/bert_models\n","2021-07-07 19:43:49.709 INFO in 'deeppavlov.core.data.utils'['utils'] at line 95: Downloading from http://files.deeppavlov.ai/kbqa/datasets/entity_and_type_detection_rus.pickle to /root/.deeppavlov/models/entity_and_type_detection_rus.pickle\n","100%|██████████| 2.07M/2.07M [00:00<00:00, 2.54MB/s]\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package perluniprops to /root/nltk_data...\n","[nltk_data]   Unzipping misc/perluniprops.zip.\n","[nltk_data] Downloading package nonbreaking_prefixes to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["2021-07-07 19:43:56.510 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/ner_ent_and_type_rus/tag.dict]\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:37: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:193: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:236: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:314: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:178: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:418: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:499: The name tf.assert_less_equal is deprecated. Please use tf.compat.v1.assert_less_equal instead.\n","\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:366: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:680: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use keras.layers.Dense instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert_dp/modeling.py:283: The name tf.erf is deprecated. Please use tf.math.erf instead.\n","\n","WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:75: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:571: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:131: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:94: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:671: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:244: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/models/bert/bert_sequence_tagger.py:249: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n"],"name":"stdout"},{"output_type":"stream","text":["2021-07-07 19:44:29.118 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 51: [loading model from /root/.deeppavlov/models/ner_ent_and_type_rus/model]\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/deeppavlov/core/models/tf_model.py:54: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","INFO:tensorflow:Restoring parameters from /root/.deeppavlov/models/ner_ent_and_type_rus/model\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["[[['Нью',\n","   '-',\n","   'Йорк',\n","   ',',\n","   'США',\n","   ',',\n","   '30',\n","   'апреля',\n","   '2020',\n","   ',',\n","   '01',\n","   ':',\n","   '01',\n","   '—',\n","   'REGNUM',\n","   'В',\n","   'администрации',\n","   'президента',\n","   'США',\n","   'Дональда',\n","   'Трампа',\n","   'планируют',\n","   'пройти',\n","   'все',\n","   'этапы',\n","   'создания',\n","   'вакцины',\n","   'от',\n","   'коронавируса',\n","   'в',\n","   'ускоренном',\n","   'темпе',\n","   'и',\n","   'выпустить',\n","   '100',\n","   'млн',\n","   'доз',\n","   'до',\n","   'конца',\n","   '2020',\n","   'года',\n","   ',',\n","   'передаёт',\n","   'агентство',\n","   'Bloomberg',\n","   'со',\n","   'ссылкой',\n","   'на',\n","   'осведомлённые',\n","   'источники']],\n"," array([[[9.71761167e-01, 2.64181718e-02, 1.82059826e-03],\n","         [9.60046053e-01, 3.84359621e-02, 1.51804090e-03],\n","         [9.21502233e-01, 7.51483515e-02, 3.34933866e-03],\n","         [9.92245018e-01, 6.89126039e-03, 8.63717811e-04],\n","         [9.87261832e-01, 1.17831351e-02, 9.55077179e-04],\n","         [9.96919036e-01, 2.74484046e-03, 3.36058962e-04],\n","         [9.97517467e-01, 2.30196840e-03, 1.80645322e-04],\n","         [9.95577574e-01, 4.12209751e-03, 3.00363230e-04],\n","         [9.91355956e-01, 8.05664156e-03, 5.87437069e-04],\n","         [9.98594940e-01, 1.27561530e-03, 1.29398570e-04],\n","         [9.98789489e-01, 1.13862741e-03, 7.19211675e-05],\n","         [9.97291386e-01, 2.53513828e-03, 1.73508219e-04],\n","         [9.98374701e-01, 1.53756991e-03, 8.77227576e-05],\n","         [9.97647226e-01, 2.15254142e-03, 2.00248949e-04],\n","         [9.96125996e-01, 3.52644222e-03, 3.47553432e-04],\n","         [9.98647392e-01, 1.18941162e-03, 1.63180783e-04],\n","         [9.94467735e-01, 4.99971071e-03, 5.32494334e-04],\n","         [9.88695621e-01, 1.04803387e-02, 8.23963608e-04],\n","         [9.90075767e-01, 8.98968987e-03, 9.34486161e-04],\n","         [1.60550028e-01, 8.38216543e-01, 1.23350031e-03],\n","         [1.39164224e-01, 8.59113455e-01, 1.72229693e-03],\n","         [9.98087585e-01, 1.73141155e-03, 1.80948962e-04],\n","         [9.98838842e-01, 1.03886123e-03, 1.22317724e-04],\n","         [9.98723567e-01, 1.15420937e-03, 1.22209996e-04],\n","         [9.97251451e-01, 2.43649492e-03, 3.12116492e-04],\n","         [9.96265590e-01, 3.32576130e-03, 4.08622727e-04],\n","         [9.88883674e-01, 1.00314673e-02, 1.08485715e-03],\n","         [9.81114209e-01, 1.81934275e-02, 6.92377449e-04],\n","         [3.06576163e-01, 6.90057814e-01, 3.36598023e-03],\n","         [9.96585727e-01, 3.16357287e-03, 2.50688347e-04],\n","         [9.96187031e-01, 3.55201564e-03, 2.60923203e-04],\n","         [9.94267046e-01, 5.20009315e-03, 5.32936596e-04],\n","         [9.98957992e-01, 9.21283732e-04, 1.20748897e-04],\n","         [9.98963594e-01, 9.19635117e-04, 1.16777301e-04],\n","         [9.94871259e-01, 4.77636745e-03, 3.52344301e-04],\n","         [9.92532551e-01, 6.92349765e-03, 5.44037437e-04],\n","         [9.94569838e-01, 4.95819980e-03, 4.71973879e-04],\n","         [9.98663902e-01, 1.20707951e-03, 1.29073000e-04],\n","         [9.97741580e-01, 2.10796879e-03, 1.50471955e-04],\n","         [9.95123923e-01, 4.60237823e-03, 2.73693877e-04],\n","         [9.98261988e-01, 1.58725481e-03, 1.50823776e-04],\n","         [9.98117447e-01, 1.66510267e-03, 2.17488472e-04],\n","         [9.98956561e-01, 9.41986626e-04, 1.01515136e-04],\n","         [9.94731545e-01, 4.65001678e-03, 6.18365128e-04],\n","         [8.65644813e-01, 1.27655372e-01, 6.69975672e-03],\n","         [9.98962879e-01, 9.61940445e-04, 7.51710177e-05],\n","         [9.99106348e-01, 8.36298510e-04, 5.72500976e-05],\n","         [9.98937190e-01, 9.87627311e-04, 7.51964762e-05],\n","         [9.96844649e-01, 2.94215581e-03, 2.13187697e-04],\n","         [9.94291425e-01, 5.16543631e-03, 5.43111411e-04]]], dtype=float32)]"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"markdown","metadata":{"id":"WX2OpqJir_7b"},"source":["#### 3.написать свой нер попробовать разные подходы (с доп информацией без) так же с учётом соседей и без них"]},{"cell_type":"code","metadata":{"id":"XQ1phPKisJMz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625687153141,"user_tz":-180,"elapsed":15955,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"195ca629-ba7f-4de0-ede3-c9c6c8f38e83"},"source":["!pip -q install spacy\n","!python -m spacy download en\n","!python -m spacy download en_core_web_sm"],"execution_count":57,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.0.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.0)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.5.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.7/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n","Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n","Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.0.0)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.18.0)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.22.0)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.5.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lEz-r7sKsf-z","executionInfo":{"status":"ok","timestamp":1625687184967,"user_tz":-180,"elapsed":24818,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"415c997c-e9be-4f45-bc1c-f5ab47cf63de"},"source":["!pip install -U spacy\n","!python -m spacy info"],"execution_count":58,"outputs":[{"output_type":"stream","text":["Collecting spacy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c1/da/61f934c6ae177a291c77246ef91a78cab44a2d76f79e6892ca7b17571adf/spacy-3.1.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4MB)\n","\u001b[K     |████████████████████████████████| 6.4MB 4.2MB/s \n","\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.7\n","  Downloading https://files.pythonhosted.org/packages/d3/e8/1bc00eeff3faf1c50bde941f88a491a5c1128debb75dd8c913401e71585c/spacy_legacy-3.0.8-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.18.0)\n","Collecting thinc<8.1.0,>=8.0.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/6e/bd2da3d71ab2d175248949ac106fee09ae13bfaca39002eabdbd908b7440/thinc-8.0.7-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (619kB)\n","\u001b[K     |████████████████████████████████| 624kB 30.8MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n","Requirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n","Collecting typer<0.4.0,>=0.3.0\n","  Downloading https://files.pythonhosted.org/packages/90/34/d138832f6945432c638f32137e6c79a3b682f06a63c488dcfaca6b166c64/typer-0.3.2-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n","Requirement already satisfied, skipping upgrade: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy) (3.7.4.3)\n","Collecting srsly<3.0.0,>=2.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/84/dfdfc9f6f04f6b88207d96d9520b911e5fec0c67ff47a0dea31ab5429a1e/srsly-2.4.1-cp37-cp37m-manylinux2014_x86_64.whl (456kB)\n","\u001b[K     |████████████████████████████████| 460kB 35.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (57.0.0)\n","Requirement already satisfied, skipping upgrade: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.11.3)\n","Collecting catalogue<2.1.0,>=2.0.4\n","  Downloading https://files.pythonhosted.org/packages/9c/10/dbc1203a4b1367c7b02fddf08cb2981d9aa3e688d398f587cea0ab9e3bec/catalogue-2.0.4-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.22.0)\n","Requirement already satisfied, skipping upgrade: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n","Collecting pathy>=0.3.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/65/ae/ecfa3e2dc267010fa320034be0eb3a8e683dc98dae7e70f92b41605b4d35/pathy-0.6.0-py3-none-any.whl (42kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (20.9)\n","Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/f2/2d5425efe57f6c4e06cbe5e587c1fd16929dcf0eb90bd4d3d1e1c97d1151/pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1MB)\n","\u001b[K     |████████████████████████████████| 10.1MB 39.0MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n","Requirement already satisfied, skipping upgrade: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy) (7.1.2)\n","Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy) (2.0.1)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy) (3.4.1)\n","Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n","Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.8)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n","Requirement already satisfied, skipping upgrade: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy) (5.1.0)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy) (2.4.7)\n","\u001b[31mERROR: deeppavlov 0.15.0 has requirement pydantic==1.3, but you'll have pydantic 1.8.2 which is incompatible.\u001b[0m\n","Installing collected packages: spacy-legacy, catalogue, pydantic, srsly, thinc, typer, pathy, spacy\n","  Found existing installation: catalogue 1.0.0\n","    Uninstalling catalogue-1.0.0:\n","      Successfully uninstalled catalogue-1.0.0\n","  Found existing installation: pydantic 1.3\n","    Uninstalling pydantic-1.3:\n","      Successfully uninstalled pydantic-1.3\n","  Found existing installation: srsly 1.0.5\n","    Uninstalling srsly-1.0.5:\n","      Successfully uninstalled srsly-1.0.5\n","  Found existing installation: thinc 7.4.0\n","    Uninstalling thinc-7.4.0:\n","      Successfully uninstalled thinc-7.4.0\n","  Found existing installation: spacy 2.2.4\n","    Uninstalling spacy-2.2.4:\n","      Successfully uninstalled spacy-2.2.4\n","Successfully installed catalogue-2.0.4 pathy-0.6.0 pydantic-1.8.2 spacy-3.1.0 spacy-legacy-3.0.8 srsly-2.4.1 thinc-8.0.7 typer-0.3.2\n","\u001b[1m\n","============================== Info about spaCy ==============================\u001b[0m\n","\n","spaCy version    3.1.0                         \n","Location         /usr/local/lib/python3.7/dist-packages/spacy\n","Platform         Linux-5.4.104+-x86_64-with-Ubuntu-18.04-bionic\n","Python version   3.7.10                        \n","Pipelines                                      \n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jSsh6haOtKZI","executionInfo":{"status":"ok","timestamp":1625687202915,"user_tz":-180,"elapsed":12173,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"e5e61ce1-3433-4957-fd4c-6aa2397e0499"},"source":["!python -m spacy download en_core_web_md"],"execution_count":59,"outputs":[{"output_type":"stream","text":["Collecting en-core-web-md==3.1.0\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.1.0/en_core_web_md-3.1.0-py3-none-any.whl (45.4MB)\n","\u001b[K     |████████████████████████████████| 45.4MB 1.4MB/s \n","\u001b[?25hRequirement already satisfied: spacy<3.2.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-md==3.1.0) (3.1.0)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.8)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.4.1)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.8.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.0.5)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.6.0)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.18.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (57.0.0)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.4)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.7.4.3)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (4.41.1)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.4.1)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.8.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.11.3)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (8.0.7)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.22.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (20.9)\n","Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (0.3.2)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.5)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (5.1.0)\n","Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.4.1)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.0.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2021.5.30)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (3.0.4)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (2.4.7)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy<3.2.0,>=3.1.0->en-core-web-md==3.1.0) (7.1.2)\n","Installing collected packages: en-core-web-md\n","Successfully installed en-core-web-md-3.1.0\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_md')\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tRrsQRJ6s_bb","executionInfo":{"status":"ok","timestamp":1625687239200,"user_tz":-180,"elapsed":32903,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"462a8b45-0762-49c5-a854-a2e4800b6c04"},"source":["import spacy\n","from spacy import displacy\n","!pip install spacy model\n","!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.0/en_core_web_md-2.2.0.tar.gz\n","import en_core_web_md"],"execution_count":60,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (3.1.0)\n","\u001b[31mERROR: Could not find a version that satisfies the requirement model (from versions: none)\u001b[0m\n","\u001b[31mERROR: No matching distribution found for model\u001b[0m\n","Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.0/en_core_web_md-2.2.0.tar.gz\n","\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.2.0/en_core_web_md-2.2.0.tar.gz (96.4MB)\n","\u001b[K     |████████████████████████████████| 96.4MB 1.3MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-md==2.2.0) (3.1.0)\n","Requirement already satisfied: typer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (0.3.2)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (1.18.0)\n","Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (0.6.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (4.41.1)\n","Requirement already satisfied: thinc<8.1.0,>=8.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (8.0.7)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (3.0.5)\n","Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (0.4.1)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (2.0.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (20.9)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (57.0.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (2.22.0)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (2.4.1)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (2.0.5)\n","Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (3.7.4.3)\n","Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (0.8.2)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (1.0.5)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (1.8.2)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (3.0.8)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.0->en-core-web-md==2.2.0) (2.11.3)\n","Requirement already satisfied: click<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.4.0,>=0.3.0->spacy>=2.2.0->en-core-web-md==2.2.0) (7.1.2)\n","Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy>=2.2.0->en-core-web-md==2.2.0) (5.1.0)\n","Requirement already satisfied: zipp>=0.5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.4->spacy>=2.2.0->en-core-web-md==2.2.0) (3.4.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy>=2.2.0->en-core-web-md==2.2.0) (2.4.7)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-md==2.2.0) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-md==2.2.0) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-md==2.2.0) (2.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->en-core-web-md==2.2.0) (2021.5.30)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy>=2.2.0->en-core-web-md==2.2.0) (2.0.1)\n","Building wheels for collected packages: en-core-web-md\n","  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for en-core-web-md: filename=en_core_web_md-2.2.0-cp37-none-any.whl size=98072936 sha256=e9655886ccae3f882144483e8994ab24ed0ad9ae0b2ba681b6c6ad0287b77b1c\n","  Stored in directory: /root/.cache/pip/wheels/5f/3e/c9/36dd6e13b449fd84cd1f94b72dfbc559daf09f53dbf4e697a3\n","Successfully built en-core-web-md\n","Installing collected packages: en-core-web-md\n","  Found existing installation: en-core-web-md 3.1.0\n","    Uninstalling en-core-web-md-3.1.0:\n","      Successfully uninstalled en-core-web-md-3.1.0\n","Successfully installed en-core-web-md-2.2.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":387},"id":"FKGsD7aZsgHn","executionInfo":{"status":"error","timestamp":1625687244894,"user_tz":-180,"elapsed":680,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"acc5d7ac-5391-4487-9642-75cef3885b94"},"source":["nlp = en_core_web_md.load()\n","ny_bb = url_to_string('https://www.nytimes.com/2018/08/13/us/politics/peter-strzok-fired-fbi.html?hp&action=click&pgtype=Homepage&clickSource=story-heading&module=first-column-region&region=top-news&WT.nav=top-news')\n","article = nlp(ny_bb)\n","displacy.render(article, jupyter=True, style='ent')"],"execution_count":61,"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-61-38769d4bd465>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0men_core_web_md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mny_bb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.nytimes.com/2018/08/13/us/politics/peter-strzok-fired-fbi.html?hp&action=click&pgtype=Homepage&clickSource=story-heading&module=first-column-region&region=top-news&WT.nav=top-news'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mny_bb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdisplacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjupyter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ent'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/en_core_web_md/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(**overrides)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload_model_from_init_py\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_init_py\u001b[0;34m(init_file, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    521\u001b[0m         \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    522\u001b[0m         \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 523\u001b[0;31m         \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    524\u001b[0m     )\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_model_from_path\u001b[0;34m(model_path, meta, vocab, disable, exclude, config)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0mconfig_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"config.cfg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0moverrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0mnlp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model_from_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_disk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/spacy/util.py\u001b[0m in \u001b[0;36mload_config\u001b[0;34m(path, overrides, interpolate)\u001b[0m\n\u001b[1;32m    546\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig_path\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconfig_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE053\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"config.cfg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m         return config.from_disk(\n\u001b[1;32m    550\u001b[0m             \u001b[0mconfig_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: [E053] Could not read config.cfg from /usr/local/lib/python3.7/dist-packages/en_core_web_md/en_core_web_md-2.2.0/config.cfg"]}]},{"cell_type":"code","metadata":{"id":"AL4KGLXgtx_x"},"source":[""],"execution_count":null,"outputs":[]}]}