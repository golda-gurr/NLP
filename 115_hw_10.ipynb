{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"115_hw_10.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"k0IBrJKM0IrB"},"source":["# Курс Введение в обработку естественного языка\n","# Урок 10. Машинный перевод. Модель seq2seq и механизм внимания"]},{"cell_type":"markdown","metadata":{"id":"LbPwSDlH0Vao"},"source":["# Задание\n","Разобраться с моделькой перевода как она устроена (без механизма внимания), запустить для перевода с русского на английский (при желании можно взять другие пары языков)\n"]},{"cell_type":"markdown","metadata":{"id":"J0Qjg6vuaHNt"},"source":["# Решение"]},{"cell_type":"code","metadata":{"id":"tnxXKDjq3jEL","executionInfo":{"status":"ok","timestamp":1627220874467,"user_tz":-180,"elapsed":2497,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["import tensorflow as tf\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","from sklearn.model_selection import train_test_split\n","\n","import unicodedata\n","import re\n","import numpy as np\n","import os\n","import io\n","import time"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wfodePkj3jEa"},"source":["## Загрузка и установка датасета\n","\n","Возьмем датсет с языковыми парами немецкий-английский с сайта http://www.manythings.org/anki/"]},{"cell_type":"code","metadata":{"id":"CNvjhDyAKk3U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627220879398,"user_tz":-180,"elapsed":1154,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"732c9a1d-554b-47bc-8c40-06c6a57c8d7b"},"source":["!wget http://www.manythings.org/anki/deu-eng.zip"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2021-07-25 13:47:56--  http://www.manythings.org/anki/deu-eng.zip\n","Resolving www.manythings.org (www.manythings.org)... 104.21.92.44, 172.67.186.54, 2606:4700:3033::ac43:ba36, ...\n","Connecting to www.manythings.org (www.manythings.org)|104.21.92.44|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 9079830 (8.7M) [application/zip]\n","Saving to: ‘deu-eng.zip’\n","\n","deu-eng.zip         100%[===================>]   8.66M  21.3MB/s    in 0.4s    \n","\n","2021-07-25 13:47:57 (21.3 MB/s) - ‘deu-eng.zip’ saved [9079830/9079830]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"83bg17Lr-7XK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627220885905,"user_tz":-180,"elapsed":1199,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"7ca2eaab-2f5d-4d37-ea9d-4d8e1b540d98"},"source":["!mkdir deu-eng\n","!unzip deu-eng.zip -d deu-eng/"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Archive:  deu-eng.zip\n","  inflating: deu-eng/deu.txt         \n","  inflating: deu-eng/_about.txt      \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7o5L92efMMhf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627220889894,"user_tz":-180,"elapsed":928,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"ccd99a7b-ec0f-4e8e-fcb4-2415ef8a6600"},"source":["!ls /content/deu-eng/ -lah"],"execution_count":4,"outputs":[{"output_type":"stream","text":["total 36M\n","drwxr-xr-x 2 root root 4.0K Jul 25 13:48 .\n","drwxr-xr-x 1 root root 4.0K Jul 25 13:48 ..\n","-rw-r--r-- 1 root root 1.5K Jul 14 10:16 _about.txt\n","-rw-r--r-- 1 root root  36M Jul 14 10:16 deu.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kRVATYOgJs1b","executionInfo":{"status":"ok","timestamp":1627220895924,"user_tz":-180,"elapsed":262,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["# Download the file\n","path_to_file = \"/content/deu-eng/deu.txt\""],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"rd0jw-eC3jEh","executionInfo":{"status":"ok","timestamp":1627220909478,"user_tz":-180,"elapsed":254,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["def preprocess_sentence(w):\n","  w = w.lower().strip()\n","\n","  # creating a space between a word and the punctuation following it\n","  # eg: \"he is a boy.\" => \"he is a boy .\"\n","  # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n","  w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n","  w = re.sub(r'[\" \"]+', \" \", w)\n","\n","  # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n","  w = re.sub(r\"[^a-zA-Zа-яА-Я?.!,']+\", \" \", w)\n","\n","  w = w.strip()\n","\n","  # adding a start and an end token to the sentence\n","  # so that the model know when to start and stop predicting.\n","  w = '<start> ' + w + ' <end>'\n","  return w"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"yV9lZXQXNbnH","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1627220914579,"user_tz":-180,"elapsed":263,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"fae1bd91-6b98-4baa-a4f3-ef67eb702929"},"source":["preprocess_sentence(\"I can't go.\")"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"<start> i can't go . <end>\""]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"OHn4Dct23jEm","executionInfo":{"status":"ok","timestamp":1627220928269,"user_tz":-180,"elapsed":270,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["# 1. Remove the accents\n","# 2. Clean the sentences\n","# 3. Return word pairs in the format: [ENG, DEU]\n","def create_dataset(path, num_examples):\n","  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n","\n","  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')[:2]]  for l in lines[:num_examples]]\n","\n","  return zip(*word_pairs)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"cTbSbBz55QtF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627220955679,"user_tz":-180,"elapsed":6694,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"59b176fa-7241-4785-d246-df9a6b3d2184"},"source":["en, de = create_dataset(path_to_file, None)\n","print(en[0])\n","print(de[0])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["<start> go . <end>\n","<start> geh . <end>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bIOn8RCNDJXG","executionInfo":{"status":"ok","timestamp":1627220999852,"user_tz":-180,"elapsed":246,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["def tokenize(lang):\n","  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n","      filters='')\n","  lang_tokenizer.fit_on_texts(lang)\n","\n","  tensor = lang_tokenizer.texts_to_sequences(lang)\n","\n","  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n","                                                         padding='post')\n","\n","  return tensor, lang_tokenizer"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"eAY9k49G3jE_","executionInfo":{"status":"ok","timestamp":1627221006576,"user_tz":-180,"elapsed":262,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["def load_dataset(path, num_examples=None):\n","  # creating cleaned input, output pairs\n","  targ_lang, inp_lang = create_dataset(path, num_examples)\n","\n","  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n","  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n","\n","  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GOi42V79Ydlr"},"source":["### Ограничим размер датасета для ускорения эксперимента (опционально)\n"]},{"cell_type":"code","metadata":{"id":"C8j9g9AnIeZV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627221016212,"user_tz":-180,"elapsed":266,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"24f5f4b3-fa2f-4f1f-d9b6-608aaddbb8cf"},"source":["len(en), len(de)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(242586, 242586)"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"cnxC7q-j3jFD","executionInfo":{"status":"ok","timestamp":1627221031796,"user_tz":-180,"elapsed":6650,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["# Try experimenting with the size of that dataset\n","num_examples = 100000\n","input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n","\n","# Calculate max_length of the target tensors\n","max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"4QILQkOs3jFG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627221038101,"user_tz":-180,"elapsed":263,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"b3751f36-d7f6-4285-af72-bb28558d6d4e"},"source":["# Creating training and validation sets using an 80-20 split\n","input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n","\n","# Show length\n","print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["80000 80000 20000 20000\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lJPmLZGMeD5q","executionInfo":{"status":"ok","timestamp":1627221045686,"user_tz":-180,"elapsed":266,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["def convert(lang, tensor):\n","  for t in tensor:\n","    if t!=0:\n","      print (\"%d ----> %s\" % (t, lang.index_word[t]))"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"VXukARTDd7MT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627221052816,"user_tz":-180,"elapsed":253,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"c79bd65d-c6bd-4616-b0bc-1928a823d79c"},"source":["print (\"Input Language; index to word mapping\")\n","convert(inp_lang, input_tensor_train[0])\n","print ()\n","print (\"Target Language; index to word mapping\")\n","convert(targ_lang, target_tensor_train[0])"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Input Language; index to word mapping\n","1 ----> <start>\n","16 ----> er\n","1056 ----> fragte\n","24 ----> mich\n","12 ----> ,\n","678 ----> ob\n","4 ----> ich\n","165 ----> besch\n","186 ----> ftigt\n","23 ----> bin\n","3 ----> .\n","2 ----> <end>\n","\n","Target Language; index to word mapping\n","1 ----> <start>\n","16 ----> he\n","247 ----> asked\n","15 ----> me\n","275 ----> if\n","5 ----> i\n","20 ----> was\n","140 ----> busy\n","3 ----> .\n","2 ----> <end>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"rgCLkfv5uO3d"},"source":["### Создание tf.data dataset"]},{"cell_type":"code","metadata":{"id":"TqHsArVZ3jFS","executionInfo":{"status":"ok","timestamp":1627221094604,"user_tz":-180,"elapsed":5814,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["BUFFER_SIZE = len(input_tensor_train)\n","BATCH_SIZE = 64\n","steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n","embedding_dim = 300\n","units = 1024\n","vocab_inp_size = len(inp_lang.word_index)+1\n","vocab_tar_size = len(targ_lang.word_index)+1\n","\n","dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n","dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"qc6-NK1GtWQt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627221099572,"user_tz":-180,"elapsed":273,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"f8a9363a-48eb-4df1-e386-cec8f738f7c1"},"source":["example_input_batch, example_target_batch = next(iter(dataset))\n","example_input_batch.shape, example_target_batch.shape"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(TensorShape([64, 23]), TensorShape([64, 12]))"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"nZ2rI24i3jFg","executionInfo":{"status":"ok","timestamp":1627221213905,"user_tz":-180,"elapsed":248,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["class Encoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n","    super(Encoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.enc_units = enc_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(self.enc_units,\n","                                   return_sequences=False,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","\n","\n","  def call(self, x, hidden):\n","    x = self.embedding(x)\n","    output, state = self.gru(x, initial_state = hidden)\n","    return state\n","\n","  def initialize_hidden_state(self):\n","    return tf.zeros((self.batch_sz, self.enc_units))"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"60gSVh05Jl6l","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627221229033,"user_tz":-180,"elapsed":3201,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"e95aa7c1-60bd-443d-8a97-bc0ac724f1a8"},"source":["encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n","\n","# sample input\n","sample_hidden = encoder.initialize_hidden_state()\n","sample_hidden = encoder(example_input_batch, sample_hidden)\n","# print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n","print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Encoder Hidden state shape: (batch size, units) (64, 1024)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"yJ_B3mhW3jFk","executionInfo":{"status":"ok","timestamp":1627221233243,"user_tz":-180,"elapsed":258,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["class Decoder(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n","    super(Decoder, self).__init__()\n","    self.batch_sz = batch_sz\n","    self.dec_units = dec_units\n","    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n","    self.gru = tf.keras.layers.GRU(self.dec_units,\n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","    self.fc = tf.keras.layers.Dense(vocab_size)\n","\n","  def call(self, x, hidden):\n","    # enc_output shape == (batch_size, max_length, hidden_size)\n","\n","    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n","    x = self.embedding(x)\n","\n","    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n","\n","    # passing the concatenated vector to the GRU\n","    output, state = self.gru(x, initial_state=hidden) # скрытый вектор передается из энкодера\n","\n","    # output shape == (batch_size * 1, hidden_size)\n","    output = tf.reshape(output, (-1, output.shape[2]))\n","\n","    # output shape == (batch_size, vocab)\n","    x = self.fc(output)\n","\n","    return x, state"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"P5UY8wko3jFp","executionInfo":{"status":"ok","timestamp":1627221240197,"user_tz":-180,"elapsed":2894,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n","\n","decoder_sample_x, decoder_sample_h = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n","                                      sample_hidden)"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XKcypC0AGeLR","executionInfo":{"status":"ok","timestamp":1627221242809,"user_tz":-180,"elapsed":291,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"b00fd4c8-4bcd-4ba1-c0be-ae2733d34b90"},"source":["decoder_sample_x.shape"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 8830])"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"6y0HF-zMF_vp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627221244902,"user_tz":-180,"elapsed":273,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"62a793bc-0bee-4aff-86b8-5aa10b5f6bd2"},"source":["decoder_sample_h.shape"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([64, 1024])"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"markdown","metadata":{"id":"_ch_71VbIRfK"},"source":["## Определение оптимайзера и функции потерь"]},{"cell_type":"code","metadata":{"id":"WmTHr5iV3jFr","executionInfo":{"status":"ok","timestamp":1627221249878,"user_tz":-180,"elapsed":255,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["optimizer = tf.keras.optimizers.Adam()\n","\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n","    from_logits=True, reduction='none')\n","\n","def loss_function(real, pred):\n","  mask = tf.math.logical_not(tf.math.equal(real, 0))\n","  loss_ = loss_object(real, pred)\n","\n","  mask = tf.cast(mask, dtype=loss_.dtype)\n","  loss_ *= mask\n","\n","  return tf.reduce_mean(loss_)"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DMVWzzsfNl4e"},"source":["## Контрольные точки (Object-based saving)"]},{"cell_type":"code","metadata":{"id":"Zj8bXQTgNwrF","executionInfo":{"status":"ok","timestamp":1627221254065,"user_tz":-180,"elapsed":258,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["checkpoint_dir = './training_nmt_checkpoints'\n","\n","checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n","\n","checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n","                                 encoder=encoder,\n","                                 decoder=decoder)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"sC9ArXSsVfqn","executionInfo":{"status":"ok","timestamp":1627221258670,"user_tz":-180,"elapsed":257,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["@tf.function\n","def train_step(inp, targ, enc_hidden):\n","  loss = 0\n","\n","  with tf.GradientTape() as tape:\n","    enc_hidden = encoder(inp, enc_hidden)\n","\n","    dec_hidden = enc_hidden\n","\n","    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n","\n","    # Teacher forcing - feeding the target as the next input\n","    for t in range(1, targ.shape[1]):\n","      # passing enc_output to the decoder\n","      predictions, dec_hidden = decoder(dec_input, dec_hidden)\n","\n","      loss += loss_function(targ[:, t], predictions)\n","\n","      # using teacher forcing\n","      dec_input = tf.expand_dims(targ[:, t], 1)\n","\n","  batch_loss = (loss / int(targ.shape[1]))\n","\n","  variables = encoder.trainable_variables + decoder.trainable_variables\n","\n","  gradients = tape.gradient(loss, variables)\n","\n","  optimizer.apply_gradients(zip(gradients, variables))\n","\n","  return batch_loss"],"execution_count":29,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nY_0Dn1R4P8I"},"source":["## Обучение модели"]},{"cell_type":"code","metadata":{"id":"ddefjBMa3jF0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627221874080,"user_tz":-180,"elapsed":600218,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"f320dacd-fe69-46a9-f9c9-67c273513b31"},"source":["EPOCHS = 5\n","# EPOCHS = 50\n","\n","for epoch in range(EPOCHS):\n","  start = time.time()\n","\n","  enc_hidden = encoder.initialize_hidden_state()\n","  total_loss = 0\n","\n","  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n","    batch_loss = train_step(inp, targ, enc_hidden)\n","    total_loss += batch_loss\n","\n","    if batch % 100 == 0:\n","      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n","                                                   batch,\n","                                                   batch_loss.numpy()))\n","  # saving (checkpoint) the model every 2 epochs\n","  if (epoch + 1) % 2 == 0:\n","    checkpoint.save(file_prefix = checkpoint_prefix)\n","\n","  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n","                                      total_loss / steps_per_epoch))\n","  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Epoch 1 Batch 0 Loss 4.9097\n","Epoch 1 Batch 100 Loss 2.1874\n","Epoch 1 Batch 200 Loss 1.9870\n","Epoch 1 Batch 300 Loss 1.8383\n","Epoch 1 Batch 400 Loss 1.7439\n","Epoch 1 Batch 500 Loss 1.7350\n","Epoch 1 Batch 600 Loss 1.6687\n","Epoch 1 Batch 700 Loss 1.5227\n","Epoch 1 Batch 800 Loss 1.5854\n","Epoch 1 Batch 900 Loss 1.4707\n","Epoch 1 Batch 1000 Loss 1.4563\n","Epoch 1 Batch 1100 Loss 1.4272\n","Epoch 1 Batch 1200 Loss 1.1436\n","Epoch 1 Loss 1.6703\n","Time taken for 1 epoch 126.97923183441162 sec\n","\n","Epoch 2 Batch 0 Loss 1.1321\n","Epoch 2 Batch 100 Loss 1.0938\n","Epoch 2 Batch 200 Loss 1.0327\n","Epoch 2 Batch 300 Loss 1.0446\n","Epoch 2 Batch 400 Loss 1.0758\n","Epoch 2 Batch 500 Loss 1.0390\n","Epoch 2 Batch 600 Loss 1.0009\n","Epoch 2 Batch 700 Loss 0.9665\n","Epoch 2 Batch 800 Loss 0.8906\n","Epoch 2 Batch 900 Loss 0.9039\n","Epoch 2 Batch 1000 Loss 0.8757\n","Epoch 2 Batch 1100 Loss 0.8516\n","Epoch 2 Batch 1200 Loss 0.8762\n","Epoch 2 Loss 0.9986\n","Time taken for 1 epoch 119.08104681968689 sec\n","\n","Epoch 3 Batch 0 Loss 0.7205\n","Epoch 3 Batch 100 Loss 0.7066\n","Epoch 3 Batch 200 Loss 0.7203\n","Epoch 3 Batch 300 Loss 0.6678\n","Epoch 3 Batch 400 Loss 0.6178\n","Epoch 3 Batch 500 Loss 0.6068\n","Epoch 3 Batch 600 Loss 0.6305\n","Epoch 3 Batch 700 Loss 0.6523\n","Epoch 3 Batch 800 Loss 0.6770\n","Epoch 3 Batch 900 Loss 0.5903\n","Epoch 3 Batch 1000 Loss 0.5955\n","Epoch 3 Batch 1100 Loss 0.5937\n","Epoch 3 Batch 1200 Loss 0.6222\n","Epoch 3 Loss 0.6332\n","Time taken for 1 epoch 118.66937732696533 sec\n","\n","Epoch 4 Batch 0 Loss 0.3311\n","Epoch 4 Batch 100 Loss 0.4462\n","Epoch 4 Batch 200 Loss 0.3695\n","Epoch 4 Batch 300 Loss 0.4379\n","Epoch 4 Batch 400 Loss 0.4038\n","Epoch 4 Batch 500 Loss 0.3960\n","Epoch 4 Batch 600 Loss 0.3467\n","Epoch 4 Batch 700 Loss 0.3948\n","Epoch 4 Batch 800 Loss 0.4038\n","Epoch 4 Batch 900 Loss 0.3869\n","Epoch 4 Batch 1000 Loss 0.3264\n","Epoch 4 Batch 1100 Loss 0.4048\n","Epoch 4 Batch 1200 Loss 0.3781\n","Epoch 4 Loss 0.4008\n","Time taken for 1 epoch 118.36512517929077 sec\n","\n","Epoch 5 Batch 0 Loss 0.2117\n","Epoch 5 Batch 100 Loss 0.1962\n","Epoch 5 Batch 200 Loss 0.2308\n","Epoch 5 Batch 300 Loss 0.1969\n","Epoch 5 Batch 400 Loss 0.2158\n","Epoch 5 Batch 500 Loss 0.2797\n","Epoch 5 Batch 600 Loss 0.2594\n","Epoch 5 Batch 700 Loss 0.2568\n","Epoch 5 Batch 800 Loss 0.3121\n","Epoch 5 Batch 900 Loss 0.2560\n","Epoch 5 Batch 1000 Loss 0.2524\n","Epoch 5 Batch 1100 Loss 0.2081\n","Epoch 5 Batch 1200 Loss 0.2532\n","Epoch 5 Loss 0.2661\n","Time taken for 1 epoch 116.79764652252197 sec\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mU3Ce8M6I3rz"},"source":["## Перевод\n","\n","* Функция оценки похожа на тренировочную петлю, но мы не используем здесь обучение с учителем. Вход в декодер на каждом шаге времени - это его предыдущие предсказания наряду со скрытым состоянием и выходом энкодера.\n","* Предсказание останавливается, когда модель предсказывает токен *end*.\n","* И сохраняются веса внимания на каждом временном шаге.\n","\n","Примечание: Выход энкодера калькулируется единожды для одного входа."]},{"cell_type":"code","metadata":{"id":"EbQpyYs13jF_","executionInfo":{"status":"ok","timestamp":1627221882210,"user_tz":-180,"elapsed":279,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["def evaluate(sentence):\n","  attention_plot = np.zeros((max_length_targ, max_length_inp))\n","\n","  sentence = preprocess_sentence(sentence)\n","\n","  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n","  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n","                                                         maxlen=max_length_inp,\n","                                                         padding='post')\n","  inputs = tf.convert_to_tensor(inputs)\n","\n","  result = ''\n","\n","  hidden = [tf.zeros((1, units))]\n","  enc_hidden = encoder(inputs, hidden)\n","\n","  dec_hidden = enc_hidden\n","  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n","\n","  for t in range(max_length_targ):\n","    predictions, dec_hidden = decoder(dec_input, dec_hidden)\n","\n","    # storing the attention weights to plot later on\n","    predicted_id = tf.argmax(predictions[0]).numpy()\n","    result += targ_lang.index_word[predicted_id] + ' '\n","\n","    if targ_lang.index_word[predicted_id] == '<end>':\n","      return result, sentence\n","\n","    # the predicted ID is fed back into the model\n","    dec_input = tf.expand_dims([predicted_id], 0)\n","\n","  return result, sentence"],"execution_count":31,"outputs":[]},{"cell_type":"code","metadata":{"id":"sl9zUHzg3jGI","executionInfo":{"status":"ok","timestamp":1627221885692,"user_tz":-180,"elapsed":291,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}}},"source":["def translate(sentence):\n","  result, sentence = evaluate(sentence)\n","\n","  print('Input: %s' % (sentence))\n","  print('Predicted translation: {}'.format(result))"],"execution_count":32,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"n250XbnjOaqP"},"source":["## Восстановление последней контрольной точки и тест"]},{"cell_type":"code","metadata":{"id":"UJpT9D5_OgP6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627221888519,"user_tz":-180,"elapsed":260,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"1d857ead-7241-4df7-9e3b-87e9ced3e033"},"source":["# restoring the latest checkpoint in checkpoint_dir\n","checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fa0044a8e50>"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"WrAM0FDomq3E","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627221890726,"user_tz":-180,"elapsed":276,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"f5947423-9ad4-42fe-a6a7-0c6aee59d27c"},"source":["translate('Sehr gut.')"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Input: <start> sehr gut . <end>\n","Predicted translation: the good are good . <end> \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5bhFfwcIMX5i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627221896927,"user_tz":-180,"elapsed":267,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"2c5c92c8-2184-4371-e231-65e446918a60"},"source":["translate('Ich kann nicht gehen.')"],"execution_count":35,"outputs":[{"output_type":"stream","text":["Input: <start> ich kann nicht gehen . <end>\n","Predicted translation: i can't walk . <end> \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zSx2iM36EZQZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627221901933,"user_tz":-180,"elapsed":278,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"32239188-dbc4-4894-9594-0574bb0cd50a"},"source":["translate(u'Sind Sie noch zu Hause?')"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Input: <start> sind sie noch zu hause ? <end>\n","Predicted translation: are you still home ? <end> \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A3LLCx3ZE0Ls","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627221906250,"user_tz":-180,"elapsed":258,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"e1e18ca9-43f5-4661-b231-5ee02a8920c3"},"source":["translate(u'Haben Sie das Haus verlassen?')"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Input: <start> haben sie das haus verlassen ? <end>\n","Predicted translation: did you close this house ? <end> \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DUQVLVqUE1YW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627221915415,"user_tz":-180,"elapsed":253,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"df4b42ef-a3f6-41ac-d9b2-18cf00635feb"},"source":["translate(u'Versuchen Sie es zu tun.')"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Input: <start> versuchen sie es zu tun . <end>\n","Predicted translation: try to do it . <end> \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"f09_hUFx9EJh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627221926525,"user_tz":-180,"elapsed":267,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"ab51aae3-088d-4682-906d-6e3e09ed23c8"},"source":["translate(u'Ich Liebe es, wenn es schneit.')"],"execution_count":39,"outputs":[{"output_type":"stream","text":["Input: <start> ich liebe es , wenn es schneit . <end>\n","Predicted translation: i love it when it goes . <end> \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"e7c5p8rmkHQG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627221935796,"user_tz":-180,"elapsed":314,"user":{"displayName":"Olga Gurr","photoUrl":"","userId":"01511282637848373828"}},"outputId":"9c3cc186-31ec-4675-9164-cb5035fae66f"},"source":["translate(u'Das mache ich nie.')"],"execution_count":40,"outputs":[{"output_type":"stream","text":["Input: <start> das mache ich nie . <end>\n","Predicted translation: i'm never going to do that . <end> \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jdXES85KkTVS"},"source":[""],"execution_count":null,"outputs":[]}]}